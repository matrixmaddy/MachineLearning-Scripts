{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.366982</td>\n",
       "      <td>-0.235416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.764044</td>\n",
       "      <td>-0.345633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  label\n",
       "0  1.366982 -0.235416      1\n",
       "1  1.764044 -0.345633      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# scatter plot, dots colored by class value\n",
    "df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * X.shape[0])\n",
    "\n",
    "train_x = X[0:train_size,]\n",
    "test_x = X[train_size:,]\n",
    "train_y = y[0:train_size,]\n",
    "test_y = y[train_size:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 2), (30, 2))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70,), (30,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu',input_dim = 2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.2091 - acc: 0.8857 - val_loss: 0.3847 - val_acc: 0.8667\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.2084 - acc: 0.8857 - val_loss: 0.3858 - val_acc: 0.8667\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.2081 - acc: 0.8857 - val_loss: 0.3880 - val_acc: 0.8667\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.2077 - acc: 0.8857 - val_loss: 0.3900 - val_acc: 0.8667\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.2077 - acc: 0.8857 - val_loss: 0.3927 - val_acc: 0.8667\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.2075 - acc: 0.8857 - val_loss: 0.3990 - val_acc: 0.8667\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.2077 - acc: 0.9000 - val_loss: 0.4027 - val_acc: 0.8667\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2078 - acc: 0.9000 - val_loss: 0.4040 - val_acc: 0.8667\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.2071 - acc: 0.9000 - val_loss: 0.4007 - val_acc: 0.8667\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.2065 - acc: 0.9000 - val_loss: 0.4011 - val_acc: 0.8667\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.2061 - acc: 0.9000 - val_loss: 0.4063 - val_acc: 0.8333\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.2063 - acc: 0.9000 - val_loss: 0.4097 - val_acc: 0.8333\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.2061 - acc: 0.9000 - val_loss: 0.4116 - val_acc: 0.8333\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.2060 - acc: 0.9000 - val_loss: 0.4140 - val_acc: 0.8333\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2061 - acc: 0.9000 - val_loss: 0.4161 - val_acc: 0.8333\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2070 - acc: 0.9143 - val_loss: 0.4193 - val_acc: 0.8000\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2062 - acc: 0.9143 - val_loss: 0.4166 - val_acc: 0.8000\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.2052 - acc: 0.9143 - val_loss: 0.4084 - val_acc: 0.8333\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.2039 - acc: 0.9143 - val_loss: 0.3978 - val_acc: 0.8667\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.2023 - acc: 0.9143 - val_loss: 0.3872 - val_acc: 0.8667\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2023 - acc: 0.9000 - val_loss: 0.3812 - val_acc: 0.8667\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.2010 - acc: 0.9000 - val_loss: 0.3815 - val_acc: 0.8667\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2011 - acc: 0.9000 - val_loss: 0.3799 - val_acc: 0.8667\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2002 - acc: 0.9000 - val_loss: 0.3842 - val_acc: 0.8667\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 99us/step - loss: 0.1993 - acc: 0.9143 - val_loss: 0.3840 - val_acc: 0.8667\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1990 - acc: 0.9143 - val_loss: 0.3846 - val_acc: 0.8667\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1986 - acc: 0.9143 - val_loss: 0.3919 - val_acc: 0.8667\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.1987 - acc: 0.9143 - val_loss: 0.3974 - val_acc: 0.8667\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.1994 - acc: 0.9143 - val_loss: 0.3999 - val_acc: 0.8333\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.1986 - acc: 0.9143 - val_loss: 0.3989 - val_acc: 0.8667\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.1980 - acc: 0.9143 - val_loss: 0.3961 - val_acc: 0.8667\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1972 - acc: 0.9143 - val_loss: 0.3924 - val_acc: 0.8667\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.1963 - acc: 0.9000 - val_loss: 0.3874 - val_acc: 0.8667\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1956 - acc: 0.9000 - val_loss: 0.3803 - val_acc: 0.8667\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.1945 - acc: 0.9000 - val_loss: 0.3727 - val_acc: 0.8667\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1941 - acc: 0.9000 - val_loss: 0.3700 - val_acc: 0.8667\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.1937 - acc: 0.9000 - val_loss: 0.3693 - val_acc: 0.8667\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.1932 - acc: 0.9143 - val_loss: 0.3659 - val_acc: 0.8667\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1927 - acc: 0.9143 - val_loss: 0.3609 - val_acc: 0.8667\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 113us/step - loss: 0.1929 - acc: 0.9143 - val_loss: 0.3574 - val_acc: 0.9000\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.1925 - acc: 0.9143 - val_loss: 0.3566 - val_acc: 0.9000\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.1922 - acc: 0.9143 - val_loss: 0.3571 - val_acc: 0.9000\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.1914 - acc: 0.9143 - val_loss: 0.3558 - val_acc: 0.9000\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1908 - acc: 0.9143 - val_loss: 0.3570 - val_acc: 0.9000\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1904 - acc: 0.9143 - val_loss: 0.3561 - val_acc: 0.9000\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.1898 - acc: 0.9143 - val_loss: 0.3528 - val_acc: 0.9000\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1902 - acc: 0.9143 - val_loss: 0.3514 - val_acc: 0.9000\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1894 - acc: 0.9143 - val_loss: 0.3533 - val_acc: 0.9000\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1885 - acc: 0.9143 - val_loss: 0.3574 - val_acc: 0.9000\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1876 - acc: 0.9143 - val_loss: 0.3644 - val_acc: 0.8667\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1872 - acc: 0.9143 - val_loss: 0.3702 - val_acc: 0.8667\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1873 - acc: 0.9143 - val_loss: 0.3705 - val_acc: 0.8667\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1861 - acc: 0.9143 - val_loss: 0.3641 - val_acc: 0.8667\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1860 - acc: 0.9143 - val_loss: 0.3600 - val_acc: 0.9000\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.1857 - acc: 0.9143 - val_loss: 0.3581 - val_acc: 0.9000\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.1850 - acc: 0.9143 - val_loss: 0.3562 - val_acc: 0.9000\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.1845 - acc: 0.9143 - val_loss: 0.3501 - val_acc: 0.9000\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.1841 - acc: 0.9286 - val_loss: 0.3464 - val_acc: 0.9000\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1839 - acc: 0.9286 - val_loss: 0.3423 - val_acc: 0.9000\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1841 - acc: 0.9286 - val_loss: 0.3379 - val_acc: 0.9000\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1846 - acc: 0.9286 - val_loss: 0.3363 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1841 - acc: 0.9286 - val_loss: 0.3372 - val_acc: 0.9000\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1827 - acc: 0.9286 - val_loss: 0.3404 - val_acc: 0.9000\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.1814 - acc: 0.9286 - val_loss: 0.3449 - val_acc: 0.9000\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1798 - acc: 0.9286 - val_loss: 0.3502 - val_acc: 0.9000\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1786 - acc: 0.9286 - val_loss: 0.3572 - val_acc: 0.9000\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1800 - acc: 0.9286 - val_loss: 0.3660 - val_acc: 0.8667\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1789 - acc: 0.9143 - val_loss: 0.3715 - val_acc: 0.8667\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1789 - acc: 0.9143 - val_loss: 0.3758 - val_acc: 0.8667\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1788 - acc: 0.9143 - val_loss: 0.3819 - val_acc: 0.8667\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1801 - acc: 0.9143 - val_loss: 0.3844 - val_acc: 0.8667\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1795 - acc: 0.9143 - val_loss: 0.3780 - val_acc: 0.8667\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1779 - acc: 0.9143 - val_loss: 0.3698 - val_acc: 0.8667\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1763 - acc: 0.9143 - val_loss: 0.3619 - val_acc: 0.8667\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1760 - acc: 0.9000 - val_loss: 0.3509 - val_acc: 0.9000\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1736 - acc: 0.9286 - val_loss: 0.3402 - val_acc: 0.9000\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1754 - acc: 0.9286 - val_loss: 0.3293 - val_acc: 0.9000\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1768 - acc: 0.9286 - val_loss: 0.3260 - val_acc: 0.9000\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1769 - acc: 0.9286 - val_loss: 0.3287 - val_acc: 0.9000\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1744 - acc: 0.9286 - val_loss: 0.3324 - val_acc: 0.9000\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.1720 - acc: 0.9286 - val_loss: 0.3365 - val_acc: 0.9000\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1717 - acc: 0.9429 - val_loss: 0.3426 - val_acc: 0.9000\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1714 - acc: 0.9429 - val_loss: 0.3465 - val_acc: 0.9000\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.1699 - acc: 0.9429 - val_loss: 0.3448 - val_acc: 0.9000\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1692 - acc: 0.9429 - val_loss: 0.3436 - val_acc: 0.9000\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1687 - acc: 0.9429 - val_loss: 0.3406 - val_acc: 0.9000\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1679 - acc: 0.9429 - val_loss: 0.3390 - val_acc: 0.9000\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.1676 - acc: 0.9429 - val_loss: 0.3364 - val_acc: 0.9000\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1671 - acc: 0.9429 - val_loss: 0.3359 - val_acc: 0.9000\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1666 - acc: 0.9429 - val_loss: 0.3377 - val_acc: 0.9000\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1658 - acc: 0.9429 - val_loss: 0.3410 - val_acc: 0.9000\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1654 - acc: 0.9429 - val_loss: 0.3439 - val_acc: 0.9000\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1648 - acc: 0.9429 - val_loss: 0.3428 - val_acc: 0.9000\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1642 - acc: 0.9429 - val_loss: 0.3385 - val_acc: 0.9000\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1631 - acc: 0.9429 - val_loss: 0.3320 - val_acc: 0.9000\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1637 - acc: 0.9429 - val_loss: 0.3262 - val_acc: 0.9000\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1633 - acc: 0.9429 - val_loss: 0.3221 - val_acc: 0.9000\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1630 - acc: 0.9429 - val_loss: 0.3205 - val_acc: 0.9333\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1625 - acc: 0.9429 - val_loss: 0.3200 - val_acc: 0.9333\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1622 - acc: 0.9429 - val_loss: 0.3191 - val_acc: 0.9333\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1616 - acc: 0.9429 - val_loss: 0.3192 - val_acc: 0.9333\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1612 - acc: 0.9429 - val_loss: 0.3203 - val_acc: 0.9333\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1602 - acc: 0.9429 - val_loss: 0.3216 - val_acc: 0.9333\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1592 - acc: 0.9429 - val_loss: 0.3222 - val_acc: 0.9333\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1586 - acc: 0.9429 - val_loss: 0.3244 - val_acc: 0.9000\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1581 - acc: 0.9429 - val_loss: 0.3253 - val_acc: 0.9000\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1570 - acc: 0.9429 - val_loss: 0.3223 - val_acc: 0.9333\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1564 - acc: 0.9429 - val_loss: 0.3211 - val_acc: 0.9333\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1557 - acc: 0.9429 - val_loss: 0.3217 - val_acc: 0.9000\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1553 - acc: 0.9429 - val_loss: 0.3246 - val_acc: 0.9000\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1542 - acc: 0.9429 - val_loss: 0.3276 - val_acc: 0.9000\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1545 - acc: 0.9429 - val_loss: 0.3310 - val_acc: 0.9000\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1535 - acc: 0.9429 - val_loss: 0.3310 - val_acc: 0.9000\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1530 - acc: 0.9429 - val_loss: 0.3316 - val_acc: 0.9000\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1524 - acc: 0.9429 - val_loss: 0.3305 - val_acc: 0.9000\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1520 - acc: 0.9429 - val_loss: 0.3299 - val_acc: 0.9000\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1509 - acc: 0.9429 - val_loss: 0.3252 - val_acc: 0.9000\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1502 - acc: 0.9429 - val_loss: 0.3207 - val_acc: 0.9333\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1496 - acc: 0.9429 - val_loss: 0.3145 - val_acc: 0.9333\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1505 - acc: 0.9429 - val_loss: 0.3130 - val_acc: 0.9333\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1489 - acc: 0.9429 - val_loss: 0.3180 - val_acc: 0.9333\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1482 - acc: 0.9429 - val_loss: 0.3234 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1482 - acc: 0.9429 - val_loss: 0.3284 - val_acc: 0.9000\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1476 - acc: 0.9429 - val_loss: 0.3311 - val_acc: 0.9000\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.1475 - acc: 0.9571 - val_loss: 0.3321 - val_acc: 0.9000\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1472 - acc: 0.9571 - val_loss: 0.3319 - val_acc: 0.9000\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1468 - acc: 0.9571 - val_loss: 0.3314 - val_acc: 0.9000\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1462 - acc: 0.9571 - val_loss: 0.3304 - val_acc: 0.9000\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1456 - acc: 0.9571 - val_loss: 0.3273 - val_acc: 0.9000\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1450 - acc: 0.9571 - val_loss: 0.3239 - val_acc: 0.9000\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1439 - acc: 0.9429 - val_loss: 0.3209 - val_acc: 0.9000\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1430 - acc: 0.9429 - val_loss: 0.3167 - val_acc: 0.9333\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1434 - acc: 0.9429 - val_loss: 0.3120 - val_acc: 0.9333\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1423 - acc: 0.9429 - val_loss: 0.3099 - val_acc: 0.9333\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1414 - acc: 0.9429 - val_loss: 0.3103 - val_acc: 0.9333\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1407 - acc: 0.9429 - val_loss: 0.3101 - val_acc: 0.9333\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.1402 - acc: 0.9429 - val_loss: 0.3068 - val_acc: 0.9333\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1393 - acc: 0.9429 - val_loss: 0.3005 - val_acc: 0.9333\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1397 - acc: 0.9429 - val_loss: 0.2956 - val_acc: 0.9333\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1392 - acc: 0.9429 - val_loss: 0.2941 - val_acc: 0.9333\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1389 - acc: 0.9429 - val_loss: 0.2941 - val_acc: 0.9333\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1383 - acc: 0.9429 - val_loss: 0.2947 - val_acc: 0.9333\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1376 - acc: 0.9429 - val_loss: 0.2972 - val_acc: 0.9333\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1359 - acc: 0.9429 - val_loss: 0.2996 - val_acc: 0.9333\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1353 - acc: 0.9429 - val_loss: 0.3027 - val_acc: 0.9333\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1352 - acc: 0.9429 - val_loss: 0.3028 - val_acc: 0.9333\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1334 - acc: 0.9429 - val_loss: 0.2968 - val_acc: 0.9333\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1332 - acc: 0.9429 - val_loss: 0.2906 - val_acc: 0.9333\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1334 - acc: 0.9429 - val_loss: 0.2845 - val_acc: 0.9333\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1349 - acc: 0.9429 - val_loss: 0.2791 - val_acc: 0.9333\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1359 - acc: 0.9429 - val_loss: 0.2773 - val_acc: 0.9333\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1354 - acc: 0.9429 - val_loss: 0.2784 - val_acc: 0.9333\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1332 - acc: 0.9429 - val_loss: 0.2831 - val_acc: 0.9333\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1308 - acc: 0.9429 - val_loss: 0.2897 - val_acc: 0.9333\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1302 - acc: 0.9429 - val_loss: 0.2967 - val_acc: 0.9333\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1291 - acc: 0.9571 - val_loss: 0.3002 - val_acc: 0.9333\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1291 - acc: 0.9571 - val_loss: 0.3036 - val_acc: 0.9333\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1289 - acc: 0.9571 - val_loss: 0.3048 - val_acc: 0.9333\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1287 - acc: 0.9571 - val_loss: 0.3056 - val_acc: 0.9333\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1282 - acc: 0.9571 - val_loss: 0.3021 - val_acc: 0.9333\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.1268 - acc: 0.9571 - val_loss: 0.2933 - val_acc: 0.9333\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.1257 - acc: 0.9571 - val_loss: 0.2884 - val_acc: 0.9333\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1259 - acc: 0.9429 - val_loss: 0.2870 - val_acc: 0.9333\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1256 - acc: 0.9429 - val_loss: 0.2888 - val_acc: 0.9333\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1245 - acc: 0.9429 - val_loss: 0.2917 - val_acc: 0.9333\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1243 - acc: 0.9571 - val_loss: 0.3001 - val_acc: 0.9333\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1250 - acc: 0.9571 - val_loss: 0.3069 - val_acc: 0.9333\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1246 - acc: 0.9571 - val_loss: 0.3083 - val_acc: 0.9333\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1244 - acc: 0.9571 - val_loss: 0.3111 - val_acc: 0.9333\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1250 - acc: 0.9571 - val_loss: 0.3127 - val_acc: 0.9333\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1241 - acc: 0.9571 - val_loss: 0.3081 - val_acc: 0.9333\n",
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1230 - acc: 0.9571 - val_loss: 0.3030 - val_acc: 0.9333\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1214 - acc: 0.9571 - val_loss: 0.2989 - val_acc: 0.9333\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1207 - acc: 0.9571 - val_loss: 0.2923 - val_acc: 0.9333\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1193 - acc: 0.9571 - val_loss: 0.2875 - val_acc: 0.9333\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1197 - acc: 0.9571 - val_loss: 0.2815 - val_acc: 0.9333\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1184 - acc: 0.9429 - val_loss: 0.2771 - val_acc: 0.9333\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1195 - acc: 0.9429 - val_loss: 0.2717 - val_acc: 0.9333\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1189 - acc: 0.9429 - val_loss: 0.2697 - val_acc: 0.9333\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1184 - acc: 0.9571 - val_loss: 0.2699 - val_acc: 0.9333\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1169 - acc: 0.9571 - val_loss: 0.2754 - val_acc: 0.9333\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1150 - acc: 0.9571 - val_loss: 0.2822 - val_acc: 0.9333\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1154 - acc: 0.9571 - val_loss: 0.2883 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1157 - acc: 0.9571 - val_loss: 0.2922 - val_acc: 0.9333\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1157 - acc: 0.9571 - val_loss: 0.2939 - val_acc: 0.9333\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.1153 - acc: 0.9571 - val_loss: 0.2927 - val_acc: 0.9333\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1148 - acc: 0.9571 - val_loss: 0.2920 - val_acc: 0.9333\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1141 - acc: 0.9571 - val_loss: 0.2936 - val_acc: 0.9333\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1141 - acc: 0.9571 - val_loss: 0.2934 - val_acc: 0.9333\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1140 - acc: 0.9571 - val_loss: 0.2907 - val_acc: 0.9333\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1132 - acc: 0.9571 - val_loss: 0.2887 - val_acc: 0.9333\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1116 - acc: 0.9571 - val_loss: 0.2801 - val_acc: 0.9333\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1098 - acc: 0.9571 - val_loss: 0.2696 - val_acc: 0.9333\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1092 - acc: 0.9714 - val_loss: 0.2619 - val_acc: 0.9333\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1103 - acc: 0.9571 - val_loss: 0.2579 - val_acc: 0.9333\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1106 - acc: 0.9571 - val_loss: 0.2564 - val_acc: 0.9333\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.1105 - acc: 0.9571 - val_loss: 0.2558 - val_acc: 0.9333\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1099 - acc: 0.9571 - val_loss: 0.2541 - val_acc: 0.9333\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1101 - acc: 0.9571 - val_loss: 0.2539 - val_acc: 0.9333\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1095 - acc: 0.9571 - val_loss: 0.2558 - val_acc: 0.9333\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1074 - acc: 0.9571 - val_loss: 0.2583 - val_acc: 0.9333\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.1060 - acc: 0.9714 - val_loss: 0.2620 - val_acc: 0.9333\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1050 - acc: 0.9714 - val_loss: 0.2661 - val_acc: 0.9333\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1048 - acc: 0.9714 - val_loss: 0.2691 - val_acc: 0.9333\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1046 - acc: 0.9714 - val_loss: 0.2717 - val_acc: 0.9333\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1045 - acc: 0.9714 - val_loss: 0.2736 - val_acc: 0.9333\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1044 - acc: 0.9714 - val_loss: 0.2741 - val_acc: 0.9333\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1040 - acc: 0.9714 - val_loss: 0.2731 - val_acc: 0.9333\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1036 - acc: 0.9714 - val_loss: 0.2711 - val_acc: 0.9333\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1028 - acc: 0.9714 - val_loss: 0.2707 - val_acc: 0.9333\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1028 - acc: 0.9714 - val_loss: 0.2718 - val_acc: 0.9333\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1023 - acc: 0.9714 - val_loss: 0.2709 - val_acc: 0.9333\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1016 - acc: 0.9714 - val_loss: 0.2674 - val_acc: 0.9333\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1009 - acc: 0.9714 - val_loss: 0.2637 - val_acc: 0.9333\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1008 - acc: 0.9714 - val_loss: 0.2611 - val_acc: 0.9333\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1001 - acc: 0.9714 - val_loss: 0.2596 - val_acc: 0.9333\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0999 - acc: 0.9714 - val_loss: 0.2570 - val_acc: 0.9333\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0995 - acc: 0.9714 - val_loss: 0.2526 - val_acc: 0.9333\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0998 - acc: 0.9571 - val_loss: 0.2510 - val_acc: 0.9333\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0993 - acc: 0.9571 - val_loss: 0.2509 - val_acc: 0.9333\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0989 - acc: 0.9714 - val_loss: 0.2520 - val_acc: 0.9333\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0979 - acc: 0.9714 - val_loss: 0.2533 - val_acc: 0.9333\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0971 - acc: 0.9714 - val_loss: 0.2542 - val_acc: 0.9333\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0965 - acc: 0.9714 - val_loss: 0.2540 - val_acc: 0.9333\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0960 - acc: 0.9714 - val_loss: 0.2536 - val_acc: 0.9333\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0956 - acc: 0.9714 - val_loss: 0.2530 - val_acc: 0.9333\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0953 - acc: 0.9714 - val_loss: 0.2521 - val_acc: 0.9333\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0949 - acc: 0.9714 - val_loss: 0.2512 - val_acc: 0.9333\n",
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0945 - acc: 0.9714 - val_loss: 0.2506 - val_acc: 0.9333\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0941 - acc: 0.9714 - val_loss: 0.2513 - val_acc: 0.9333\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0937 - acc: 0.9714 - val_loss: 0.2520 - val_acc: 0.9333\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0933 - acc: 0.9714 - val_loss: 0.2536 - val_acc: 0.9333\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0930 - acc: 0.9714 - val_loss: 0.2546 - val_acc: 0.9333\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0928 - acc: 0.9714 - val_loss: 0.2553 - val_acc: 0.9333\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0925 - acc: 0.9714 - val_loss: 0.2541 - val_acc: 0.9333\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0922 - acc: 0.9714 - val_loss: 0.2521 - val_acc: 0.9333\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0916 - acc: 0.9714 - val_loss: 0.2516 - val_acc: 0.9333\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0913 - acc: 0.9714 - val_loss: 0.2519 - val_acc: 0.9333\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0909 - acc: 0.9714 - val_loss: 0.2519 - val_acc: 0.9333\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0907 - acc: 0.9714 - val_loss: 0.2530 - val_acc: 0.9333\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0908 - acc: 0.9714 - val_loss: 0.2570 - val_acc: 0.9333\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0909 - acc: 0.9714 - val_loss: 0.2596 - val_acc: 0.9333\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0908 - acc: 0.9714 - val_loss: 0.2594 - val_acc: 0.9333\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0905 - acc: 0.9714 - val_loss: 0.2583 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0901 - acc: 0.9714 - val_loss: 0.2574 - val_acc: 0.9333\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0897 - acc: 0.9714 - val_loss: 0.2553 - val_acc: 0.9333\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0888 - acc: 0.9714 - val_loss: 0.2535 - val_acc: 0.9333\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0882 - acc: 0.9714 - val_loss: 0.2523 - val_acc: 0.9333\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0878 - acc: 0.9714 - val_loss: 0.2513 - val_acc: 0.9333\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0875 - acc: 0.9714 - val_loss: 0.2515 - val_acc: 0.9333\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0872 - acc: 0.9714 - val_loss: 0.2520 - val_acc: 0.9333\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 47us/step - loss: 0.0868 - acc: 0.9714 - val_loss: 0.2531 - val_acc: 0.9333\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0870 - acc: 0.9714 - val_loss: 0.2527 - val_acc: 0.9333\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0861 - acc: 0.9714 - val_loss: 0.2483 - val_acc: 0.9333\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0855 - acc: 0.9714 - val_loss: 0.2450 - val_acc: 0.9333\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0857 - acc: 0.9714 - val_loss: 0.2417 - val_acc: 0.9333\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0852 - acc: 0.9714 - val_loss: 0.2401 - val_acc: 0.9333\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0851 - acc: 0.9714 - val_loss: 0.2395 - val_acc: 0.9333\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0847 - acc: 0.9714 - val_loss: 0.2400 - val_acc: 0.9333\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0843 - acc: 0.9714 - val_loss: 0.2405 - val_acc: 0.9333\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0838 - acc: 0.9714 - val_loss: 0.2420 - val_acc: 0.9333\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0835 - acc: 0.9714 - val_loss: 0.2440 - val_acc: 0.9333\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0832 - acc: 0.9714 - val_loss: 0.2454 - val_acc: 0.9333\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0831 - acc: 0.9714 - val_loss: 0.2467 - val_acc: 0.9333\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0829 - acc: 0.9714 - val_loss: 0.2477 - val_acc: 0.9333\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0829 - acc: 0.9714 - val_loss: 0.2484 - val_acc: 0.9333\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0827 - acc: 0.9714 - val_loss: 0.2520 - val_acc: 0.9333\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0832 - acc: 0.9714 - val_loss: 0.2541 - val_acc: 0.9333\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0833 - acc: 0.9714 - val_loss: 0.2534 - val_acc: 0.9333\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0826 - acc: 0.9714 - val_loss: 0.2497 - val_acc: 0.9333\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0816 - acc: 0.9714 - val_loss: 0.2462 - val_acc: 0.9333\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0812 - acc: 0.9714 - val_loss: 0.2436 - val_acc: 0.9333\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0802 - acc: 0.9714 - val_loss: 0.2412 - val_acc: 0.9333\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0798 - acc: 0.9714 - val_loss: 0.2368 - val_acc: 0.9333\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0792 - acc: 0.9714 - val_loss: 0.2340 - val_acc: 0.9333\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0787 - acc: 0.9714 - val_loss: 0.2347 - val_acc: 0.9333\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0782 - acc: 0.9714 - val_loss: 0.2382 - val_acc: 0.9333\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0781 - acc: 0.9714 - val_loss: 0.2418 - val_acc: 0.9333\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0793 - acc: 0.9714 - val_loss: 0.2458 - val_acc: 0.9333\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0790 - acc: 0.9714 - val_loss: 0.2451 - val_acc: 0.9333\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 48us/step - loss: 0.0783 - acc: 0.9714 - val_loss: 0.2440 - val_acc: 0.9333\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0774 - acc: 0.9714 - val_loss: 0.2428 - val_acc: 0.9333\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0766 - acc: 0.9714 - val_loss: 0.2393 - val_acc: 0.9333\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0760 - acc: 0.9714 - val_loss: 0.2351 - val_acc: 0.9333\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0752 - acc: 0.9714 - val_loss: 0.2324 - val_acc: 0.9333\n",
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0754 - acc: 0.9714 - val_loss: 0.2301 - val_acc: 0.9333\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0749 - acc: 0.9714 - val_loss: 0.2295 - val_acc: 0.9333\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0748 - acc: 0.9714 - val_loss: 0.2294 - val_acc: 0.9333\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0745 - acc: 0.9714 - val_loss: 0.2298 - val_acc: 0.9333\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0740 - acc: 0.9714 - val_loss: 0.2301 - val_acc: 0.9333\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0738 - acc: 0.9714 - val_loss: 0.2294 - val_acc: 0.9333\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0736 - acc: 0.9714 - val_loss: 0.2271 - val_acc: 0.9333\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0731 - acc: 0.9714 - val_loss: 0.2266 - val_acc: 0.9333\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0727 - acc: 0.9714 - val_loss: 0.2262 - val_acc: 0.9333\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0725 - acc: 0.9714 - val_loss: 0.2266 - val_acc: 0.9333\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0720 - acc: 0.9714 - val_loss: 0.2271 - val_acc: 0.9333\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0718 - acc: 0.9714 - val_loss: 0.2278 - val_acc: 0.9333\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0715 - acc: 0.9714 - val_loss: 0.2280 - val_acc: 0.9333\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0711 - acc: 0.9714 - val_loss: 0.2270 - val_acc: 0.9333\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0708 - acc: 0.9714 - val_loss: 0.2268 - val_acc: 0.9333\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.2264 - val_acc: 0.9333\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0702 - acc: 0.9714 - val_loss: 0.2259 - val_acc: 0.9333\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0698 - acc: 0.9714 - val_loss: 0.2240 - val_acc: 0.9333\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0691 - acc: 0.9714 - val_loss: 0.2206 - val_acc: 0.9333\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0693 - acc: 0.9714 - val_loss: 0.2188 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0698 - acc: 0.9714 - val_loss: 0.2195 - val_acc: 0.9333\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0688 - acc: 0.9714 - val_loss: 0.2220 - val_acc: 0.9333\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0682 - acc: 0.9714 - val_loss: 0.2246 - val_acc: 0.9333\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0681 - acc: 0.9714 - val_loss: 0.2269 - val_acc: 0.9333\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0676 - acc: 0.9714 - val_loss: 0.2277 - val_acc: 0.9333\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0674 - acc: 0.9714 - val_loss: 0.2279 - val_acc: 0.9333\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0672 - acc: 0.9714 - val_loss: 0.2275 - val_acc: 0.9333\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0669 - acc: 0.9714 - val_loss: 0.2268 - val_acc: 0.9333\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0666 - acc: 0.9714 - val_loss: 0.2271 - val_acc: 0.9333\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0666 - acc: 0.9714 - val_loss: 0.2261 - val_acc: 0.9333\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0658 - acc: 0.9714 - val_loss: 0.2226 - val_acc: 0.9333\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0655 - acc: 0.9714 - val_loss: 0.2190 - val_acc: 0.9333\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0657 - acc: 0.9857 - val_loss: 0.2161 - val_acc: 0.9333\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0660 - acc: 0.9857 - val_loss: 0.2146 - val_acc: 0.9333\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0656 - acc: 0.9857 - val_loss: 0.2143 - val_acc: 0.9333\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0647 - acc: 0.9857 - val_loss: 0.2141 - val_acc: 0.9333\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0646 - acc: 0.9714 - val_loss: 0.2155 - val_acc: 0.9333\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0638 - acc: 0.9714 - val_loss: 0.2177 - val_acc: 0.9333\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0637 - acc: 0.9714 - val_loss: 0.2199 - val_acc: 0.9333\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0636 - acc: 0.9714 - val_loss: 0.2209 - val_acc: 0.9333\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0636 - acc: 0.9714 - val_loss: 0.2217 - val_acc: 0.9333\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0634 - acc: 0.9714 - val_loss: 0.2219 - val_acc: 0.9333\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0630 - acc: 0.9714 - val_loss: 0.2204 - val_acc: 0.9333\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0626 - acc: 0.9714 - val_loss: 0.2168 - val_acc: 0.9333\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0619 - acc: 0.9714 - val_loss: 0.2148 - val_acc: 0.9333\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0616 - acc: 0.9714 - val_loss: 0.2127 - val_acc: 0.9333\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0615 - acc: 0.9857 - val_loss: 0.2098 - val_acc: 0.9333\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0612 - acc: 0.9857 - val_loss: 0.2081 - val_acc: 0.9333\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0611 - acc: 0.9857 - val_loss: 0.2063 - val_acc: 0.9333\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0616 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9333\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 102us/step - loss: 0.0616 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9333\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 106us/step - loss: 0.0612 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9333\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 101us/step - loss: 0.0604 - acc: 1.0000 - val_loss: 0.2097 - val_acc: 0.9333\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0601 - acc: 1.0000 - val_loss: 0.2121 - val_acc: 0.9333\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.2139 - val_acc: 0.9333\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.2155 - val_acc: 0.9333\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0591 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9333\n",
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0590 - acc: 0.9857 - val_loss: 0.2159 - val_acc: 0.9333\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0588 - acc: 0.9857 - val_loss: 0.2155 - val_acc: 0.9333\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0587 - acc: 0.9857 - val_loss: 0.2153 - val_acc: 0.9333\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0586 - acc: 0.9714 - val_loss: 0.2146 - val_acc: 0.9333\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0582 - acc: 0.9857 - val_loss: 0.2128 - val_acc: 0.9333\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0579 - acc: 1.0000 - val_loss: 0.2121 - val_acc: 0.9333\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9333\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0574 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9333\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9333\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9333\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9333\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.2096 - val_acc: 0.9333\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0564 - acc: 1.0000 - val_loss: 0.2107 - val_acc: 0.9333\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.2128 - val_acc: 0.9333\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0558 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9333\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0557 - acc: 0.9857 - val_loss: 0.2148 - val_acc: 0.9333\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0557 - acc: 0.9857 - val_loss: 0.2153 - val_acc: 0.9333\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0556 - acc: 0.9857 - val_loss: 0.2162 - val_acc: 0.9333\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0555 - acc: 0.9857 - val_loss: 0.2146 - val_acc: 0.9333\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0552 - acc: 0.9857 - val_loss: 0.2117 - val_acc: 0.9333\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0546 - acc: 0.9857 - val_loss: 0.2111 - val_acc: 0.9333\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0542 - acc: 1.0000 - val_loss: 0.2110 - val_acc: 0.9333\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0541 - acc: 0.9857 - val_loss: 0.2110 - val_acc: 0.9333\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 71us/step - loss: 0.0540 - acc: 0.9857 - val_loss: 0.2103 - val_acc: 0.9333\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0538 - acc: 0.9714 - val_loss: 0.2099 - val_acc: 0.9333\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0536 - acc: 0.9714 - val_loss: 0.2104 - val_acc: 0.9333\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0536 - acc: 0.9714 - val_loss: 0.2110 - val_acc: 0.9333\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0535 - acc: 0.9714 - val_loss: 0.2120 - val_acc: 0.9333\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0532 - acc: 0.9714 - val_loss: 0.2118 - val_acc: 0.9333\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0532 - acc: 1.0000 - val_loss: 0.2092 - val_acc: 0.9333\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9333\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0523 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9333\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0519 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9333\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0516 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9333\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.1980 - val_acc: 0.9667\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.1954 - val_acc: 0.9667\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.1943 - val_acc: 0.9667\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 0.9667\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0520 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 0.9667\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9667\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0513 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0503 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9333\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0497 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9333\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9333\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9333\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9333\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9333\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9333\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9333\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9333\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0491 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9333\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0487 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9333\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0491 - acc: 0.9857 - val_loss: 0.2105 - val_acc: 0.9333\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0493 - acc: 0.9714 - val_loss: 0.2108 - val_acc: 0.9333\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0493 - acc: 0.9714 - val_loss: 0.2108 - val_acc: 0.9333\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0491 - acc: 0.9714 - val_loss: 0.2105 - val_acc: 0.9333\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0489 - acc: 0.9714 - val_loss: 0.2105 - val_acc: 0.9333\n",
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0488 - acc: 0.9714 - val_loss: 0.2098 - val_acc: 0.9333\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0485 - acc: 0.9714 - val_loss: 0.2090 - val_acc: 0.9333\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0482 - acc: 0.9714 - val_loss: 0.2076 - val_acc: 0.9333\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0472 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9333\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.2006 - val_acc: 0.9333\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.1990 - val_acc: 0.9667\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0466 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9667\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9667\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9667\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0458 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9333\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9333\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9333\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0452 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9333\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9333\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0452 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9333\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.2085 - val_acc: 0.9333\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9333\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.2080 - val_acc: 0.9333\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9333\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0449 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9333\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0443 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9333\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0441 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9333\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0439 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9333\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9333\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9333\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9333\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9333\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9333\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9333\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9333\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9333\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 0.9333\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9333\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0418 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9333\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0416 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9333\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.1931 - val_acc: 0.9667\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9667\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9667\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9667\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.1948 - val_acc: 0.9333\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9333\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.1942 - val_acc: 0.9333\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9333\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9333\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.1966 - val_acc: 0.9333\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9333\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9333\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9333\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9333\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.1989 - val_acc: 0.9333\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9333\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9333\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9333\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9333\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9333\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9333\n",
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9333\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.1966 - val_acc: 0.9667\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9667\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.1956 - val_acc: 0.9667\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.1955 - val_acc: 0.9667\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9667\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9667\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9667\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9667\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9667\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9667\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.1922 - val_acc: 0.9667\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9667\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9667\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9667\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.1905 - val_acc: 0.9667\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0337 - acc: 1.000 - 0s 76us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9667\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 120us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9667\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9667\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9667\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9667\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 101us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9667\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9667\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9333\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9333\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9333\n",
      "Epoch 487/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 70us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9333\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9333\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9333\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9333\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0347 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9667\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0345 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9667\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9667\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9667\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1880 - val_acc: 0.9667\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1883 - val_acc: 0.9667\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9667\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9667\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9667\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9667\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 101us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9667\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9667\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9667\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.1989 - val_acc: 0.9667\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9667\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9667\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9667\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9667\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.1959 - val_acc: 0.9667\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.1959 - val_acc: 0.9667\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9667\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9667\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9667\n",
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9667\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9667\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0317 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9667\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9667\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9667\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.1910 - val_acc: 0.9667\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9667\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9667\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9667\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9667\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9667\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9667\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 0.9667\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9667\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.1977 - val_acc: 0.9667\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9667\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9667\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9667\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9667\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9667\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9667\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.1949 - val_acc: 0.9667\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9667\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9667\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9667\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.1924 - val_acc: 0.9667\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9667\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.1927 - val_acc: 0.9667\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9667\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9667\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.1894 - val_acc: 0.9667\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9667\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9667\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9667\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9667\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9667\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1997 - val_acc: 0.9333\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9333\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9333\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9333\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9333\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9333\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9333\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9667\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.2004 - val_acc: 0.9667\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9667\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9667\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9667\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.1998 - val_acc: 0.9667\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9667\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9667\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.2003 - val_acc: 0.9667\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.2004 - val_acc: 0.9667\n",
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.9667\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.1989 - val_acc: 0.9667\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9667\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9667\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9667\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9667\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9667\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9667\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9667\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9667\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.1968 - val_acc: 0.9667\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9667\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9667\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9667\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9667\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.1964 - val_acc: 0.9667\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9667\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9667\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1927 - val_acc: 0.9667\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9667\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9667\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9667\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9667\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9667\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9667\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9667\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9667\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9667\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1943 - val_acc: 0.9667\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1954 - val_acc: 0.9667\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9667\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9667\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1979 - val_acc: 0.9667\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9667\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9667\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9667\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1998 - val_acc: 0.9667\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1985 - val_acc: 0.9667\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9667\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9667\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1949 - val_acc: 0.9667\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9667\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9667\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9667\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9667\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9667\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9667\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 48us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9667\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9667\n",
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9667\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9667\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9667\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9667\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9667\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 48us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9667\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1990 - val_acc: 0.9667\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9667\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9667\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9667\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9667\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9667\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9667\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9667\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9667\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9667\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9667\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9667\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9667\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9667\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1985 - val_acc: 0.9667\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9667\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9667\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9667\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9667\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9667\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.1911 - val_acc: 0.9667\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9667\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9667\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9667\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.1905 - val_acc: 0.9667\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.1905 - val_acc: 0.9667\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9667\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9667\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9667\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9667\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1894 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9667\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9667\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1872 - val_acc: 0.9667\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9667\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9667\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9667\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9667\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1883 - val_acc: 0.9667\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9667\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9667\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.1927 - val_acc: 0.9667\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9667\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 50us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9667\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9667\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9667\n",
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9667\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 47us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9667\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9667\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.1955 - val_acc: 0.9667\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 47us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9667\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 46us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9667\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9667\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 0.9667\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9667\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 44us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9667\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9667\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9667\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9667\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 47us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9667\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9667\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9667\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 46us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9667\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 48us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.9667\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2004 - val_acc: 0.9667\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2003 - val_acc: 0.9667\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.2003 - val_acc: 0.9667\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2006 - val_acc: 0.9667\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9667\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 47us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9667\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 45us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9667\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9667\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9667\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9667\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9667\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9667\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2021 - val_acc: 0.9667\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9667\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9667\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1980 - val_acc: 0.9667\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9667\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1977 - val_acc: 0.9667\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1985 - val_acc: 0.9667\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 49us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1997 - val_acc: 0.9667\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9667\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9667\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9667\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9667\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9667\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9667\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9667\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9667\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9667\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.2054 - val_acc: 0.9667\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9667\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9667\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9667\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9667\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9667\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9667\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9667\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9667\n",
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9667\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2021 - val_acc: 0.9667\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9667\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9667\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9667\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9667\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.9667\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9667\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9667\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9667\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9667\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9667\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2046 - val_acc: 0.9667\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 112us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9667\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9667\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9667\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9667\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9667\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9667\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9667\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9667\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9667\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9667\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9667\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9667\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9667\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9667\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9667\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9667\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9667\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9667\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2041 - val_acc: 0.9667\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9667\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9667\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9667\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.2041 - val_acc: 0.9667\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9667\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9667\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9667\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9667\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9667\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9667\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9667\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9667\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9667\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9667\n",
      "Epoch 791/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 77us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9667\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9667\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9667\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9667\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9667\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9667\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9667\n",
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9667\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9667\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9667\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9667\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2107 - val_acc: 0.9667\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.9667\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9667\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.2089 - val_acc: 0.9667\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2084 - val_acc: 0.9667\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2080 - val_acc: 0.9667\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9667\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.2089 - val_acc: 0.9667\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9667\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.2103 - val_acc: 0.9667\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.2112 - val_acc: 0.9667\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9667\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9667\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2113 - val_acc: 0.9667\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2106 - val_acc: 0.9667\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2105 - val_acc: 0.9667\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9667\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9667\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.9667\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9667\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9667\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9667\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 51us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9667\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9667\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9667\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9667\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9667\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9667\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9667\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9667\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9667\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9667\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9667\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9667\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9667\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9667\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9667\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9667\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9667\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9667\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 0.9667\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9667\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9667\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9667\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9667\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9667\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9667\n",
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9667\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9667\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9667\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9667\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9667\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2003 - val_acc: 0.9667\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9667\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9667\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 0.9667\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9667\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9667\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9667\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9667\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9667\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9667\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9667\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9667\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9667\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9667\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 105us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9667\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2084 - val_acc: 0.9667\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9667\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2103 - val_acc: 0.9667\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9667\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9667\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2113 - val_acc: 0.9667\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2119 - val_acc: 0.9667\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2124 - val_acc: 0.9667\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2128 - val_acc: 0.9667\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2132 - val_acc: 0.9667\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9667\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.2123 - val_acc: 0.9667\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.2116 - val_acc: 0.9667\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.2110 - val_acc: 0.9667\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9667\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.2112 - val_acc: 0.9667\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9667\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2107 - val_acc: 0.9667\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2097 - val_acc: 0.9667\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2089 - val_acc: 0.9667\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9667\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9667\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9667\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2046 - val_acc: 0.9667\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9667\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9667\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9667\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9667\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9667\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9667\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9667\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9667\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9667\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9667\n",
      "Epoch 912/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 66us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9667\n",
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9667\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9667\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9667\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9667\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9667\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9667\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 0.9667\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9667\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9667\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9667\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9667\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9667\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.9667\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 0.9667\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 0.9667\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9667\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.9667\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2054 - val_acc: 0.9667\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2041 - val_acc: 0.9667\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9667\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9667\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9667\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1986 - val_acc: 0.9667\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9667\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9667\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9667\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9667\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9667\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9667\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9667\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9667\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9667\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9667\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9667\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.2077 - val_acc: 0.9667\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9667\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9667\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2094 - val_acc: 0.9667\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9667\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9667\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9667\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9667\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9667\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9667\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2096 - val_acc: 0.9667\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9667\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.9667\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2110 - val_acc: 0.9667\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2116 - val_acc: 0.9667\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9667\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9667\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2154 - val_acc: 0.9667\n",
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2156 - val_acc: 0.9667\n",
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9667\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9667\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9667\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2147 - val_acc: 0.9667\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2142 - val_acc: 0.9667\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9667\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9667\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9667\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9667\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9667\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9667\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2135 - val_acc: 0.9667\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9667\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9667\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9667\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9667\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9667\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.2143 - val_acc: 0.9667\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.2147 - val_acc: 0.9667\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9667\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9667\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9667\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2136 - val_acc: 0.9667\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9667\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.2125 - val_acc: 0.9667\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2117 - val_acc: 0.9667\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2116 - val_acc: 0.9667\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.2116 - val_acc: 0.9667\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.9667\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2122 - val_acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 1000,\n",
       " 'steps': None,\n",
       " 'samples': 70,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2de5wU1ZX4v6d7Zngjr0GQh0DEyEMEHRHXKD6iQUzUqImwGjW/JGyMxsRNsupvjRo3ZpP8XKPuqglu1Oj6CItrJAnGqIFojLoMERFB5KmMKA6iyEOYme7z+6OquqtrqrtrmJ4eeup8P5/+dN1bt27f6p65p+45554jqophGIYRPxKdPQDDMAyjczABYBiGEVNMABiGYcQUEwCGYRgxxQSAYRhGTKnq7AG0hUGDBumoUaM6exiGYRgVxdKlS7eqam2wvqIEwKhRo6ivr+/sYRiGYVQUIvJmWL2pgAzDMGKKCQDDMIyYYgLAMAwjplSUDSCM5uZmGhoa2LNnT2cPpUvQvXt3hg8fTnV1dWcPxTCMDqbiBUBDQwN9+vRh1KhRiEhnD6eiUVXef/99GhoaGD16dGcPxzCMDiaSCkhE7hGR90RkRZ7zIiK3i8haEVkuIkf6zl0sImvc18W++qNE5FX3mttlH2fvPXv2MHDgQJv8S4CIMHDgQFtNGUZMiGoDuA+YUeD86cBY9zUHuAtARAYA1wPHAFOB60Wkv3vNXW5b77pC/RfEJv/SYd+lYcSHSCogVX1WREYVaHIWcL86saVfFJF+IjIUOBF4SlW3AYjIU8AMEVkM9FXVF9z6+4GzgSf28T6MSuS1x2DLSuf4sJmwdS1sfcMp1/SCY74OqxbAoTNg23p4/ffh/UgCJs+GPgfBSz+HvTvKM37DKCfH/AP0GlTSLktlAxgGbPKVG9y6QvUNIfWtEJE5OCsFRo4cWaLhdh69e/dm586dbN68mSuuuIL58+e3anPiiSdy8803U1dXl7efW2+9lTlz5tCzZ08AZs6cyUMPPUS/fv06bOwl5/HLoWmnc/zeSlj9BGgqe76qG/zhaphwDqRbHGFA2ApFIdXkCIqnvu/W2UrG6GIc/oX9VgDk+a9sc33rStW5wFyAurq6LpO95qCDDgqd/KNy6623cuGFF2YEwMKFC0s1tPLRsgc+9Y+wfhE07XIm/5OuhTHT4Zenwu73nXYfvQ09B8KQw+Hrf2ndz4+GQcteSDc75Yt/C6NPKN99GEaFUqp9AA3ACF95OLC5SP3wkPqK46qrruLOO+/MlG+44QZ+8IMfcMopp3DkkUdy+OGH8/jjj7e6buPGjUycOBGAjz/+mFmzZjFp0iTOP/98Pv7440y7Sy+9lLq6OiZMmMD1118PwO23387mzZs56aSTOOmkkwAnTMbWrVsBuOWWW5g4cSITJ07k1ltvzXzeuHHj+NrXvsaECRM47bTTcj6n7Kg6T/XJGufVvNupT1Y7L4BUc7Z9OuWoesJIVjuTf9pdPeRrZxhGDqVaASwALheRR3AMvttV9R0ReRL4kc/wexpwjapuE5EdIjINeAm4CPj39g7iB799jZWbP2pvNzmMP6gv139uQt7zs2bN4tvf/jbf+MY3AJg3bx5/+MMfuPLKK+nbty9bt25l2rRpnHnmmXkNrHfddRc9e/Zk+fLlLF++nCOPzDhRcdNNNzFgwABSqRSnnHIKy5cv54orruCWW25h0aJFDBqUuyRcunQp9957Ly+99BKqyjHHHMP06dPp378/a9as4eGHH+buu+/mi1/8Io8++igXXnhhCb6lfcCb3JNVkKiGPdvdcrVT9rcBZ3UgyfC+EtWOCshTH+VrZxhGDpEEgIg8jGPQHSQiDTiePdUAqvpzYCEwE1gL7Aa+7J7bJiL/Aixxu7rRMwgDl+J4F/XAMf5WpAF4ypQpvPfee2zevJnGxkb69+/P0KFDufLKK3n22WdJJBK8/fbbbNmyhSFDhoT28eyzz3LFFVcAMGnSJCZNmpQ5N2/ePObOnUtLSwvvvPMOK1euzDkf5C9/+Quf//zn6dWrFwDnnHMOzz33HGeeeSajR49m8uTJABx11FFs3LixRN/CPuCpa5I1zqTfvMtXrsltA87TfSLPxJ6sgVQLpNNOOV87wzByiOoFNLvIeQUuy3PuHuCekPp6YGKUz49KoSf1juS8885j/vz5vPvuu8yaNYsHH3yQxsZGli5dSnV1NaNGjSrqWx+2OtiwYQM333wzS5YsoX///lxyySVF+3F+inC6deuWOU4mk52rAko1Oe8JV+XT5KqAElXOqsDfBkDT+Z/sk1XuCsAVALYCMIxImLK0BMyaNYtHHnmE+fPnc95557F9+3YGDx5MdXU1ixYt4s03QyOxZjjhhBN48MEHAVixYgXLly8H4KOPPqJXr14ccMABbNmyhSeeyC6S+vTpw44drd0dTzjhBH7zm9+we/dudu3axWOPPcbxxx9fwrstEakW5z1ZHbAB+FYAzT4BpekCNoAaZ7WQUQGZB5BhRKHiQ0HsD0yYMIEdO3YwbNgwhg4dygUXXMDnPvc56urqmDx5MocddljB6y+99FK+/OUvM2nSJCZPnszUqVMBOOKII5gyZQoTJkxgzJgxHHfccZlr5syZw+mnn87QoUNZtGhRpv7II4/kkksuyfTx1a9+lSlTpnSuuicM7+k+We089Tft8pVdG4BXB4VVQIlqx17gGYFNBWQYkZBCKoP9jbq6Og0mhFm1ahXjxo3rpBF1TcrynX6wEW47As6+C9YtglfnOfVfuA9GT4efjoZPnAzr/gQjjnHOVXWHixe07usX06H3gTDlAph3EXz9eRhSUu2iYVQ0IrJUVVttLDIVkNE5eB4+CZ/bZ7DsXwFouoARuDrXBmArAMOIhAkAo3PIuIEGBIDfBuAZhqHIPoCaXBWQ7QMwjEjYf4rROeTYAPwCoCpb9lxDVYvsA6hyjcDmBWQYbcEEgNE5pPz7AGqy9ckaSCScSTxnBVBIBVTjCJSMEdj+rA0jCvafYpSH1U/Aq/OzE3+DuzfQ7/cP2af/pG938LvL3RVAgVAQqRbbCWwYbcTcQI2O56PN8PAs57jnQPjESfD8bU65zxDo6wsL5dkD+g6Dbeuc45Y9xWMB5WwEs+caw4iC/ae0kw8//DAnGFxUZs6cyYcfftgBI9oP8XvzNPvUOod9FgaPg6lfy9Z5AuDrf4ErX4NpTowlUnsL7wNI2z4Aw2grJgDaST4BkEqlQlpnWbhwYWXF7m8P/pAO3nG6BXoPdo79O3c9e0BNTzhguOPfD06457yhIFwvIFMBGUabMBVQO7n66qtZt24dkydPprq6mt69ezN06FCWLVvGypUrOfvss9m0aRN79uzhW9/6FnPmzAGc8M319fXs3LmT008/nU996lP89a9/ZdiwYTz++OP06NGjk++shPijenohINLNucZfj0TgT9IfFiKvEbjKdQO1fQCG0Ra6lgB44mp499XS9jnkcDj9x3lP//jHP2bFihUsW7aMxYsXc8YZZ7BixQpGjx4NwD333MOAAQP4+OOPOfroozn33HMZOHBgTh/7VZjmjiBHALgrgFRL68keWgsFTyVUdAVgNgDDaCtdSwDsB0ydOjUz+YOTvOWxxx4DYNOmTaxZs6aVANivwjR3BDlhnd3jVFP4CiCvANhTJBic3wvIBIBhRKFrCYACT+rlwovDD7B48WKefvppXnjhBXr27MmJJ54YGs55vwrT3BHk2ACa3Wxgzbk7gD2CdZlNYprfvz9RFdgHYCogw4iCPSq1k3xhmQG2b99O//796dmzJ6+//jovvvhimUe3n+Dp/cHV1ftCQQcJ1vlXBGYENoySEkkAiMgMEVktImtF5OqQ8weLyDMislxEFovIcLf+JBFZ5nvtEZGz3XP3icgG37nJpb218jBw4ECOO+44Jk6cyPe+972cczNmzKClpYVJkybx/e9/n2nTpnXSKDuZoBeQPxBckGBdziaxAsHgNJUVLLYCMIxIFFUBiUgSuAM4FSeZ+xIRWaCqK33NbgbuV9VficjJwL8CX1LVRcBkt58BOCkj/+i77nuqOr80t9J5PPTQQ6H13bp1y0ni4sfT8w8aNIgVK1Zk6r/73e+WfHydTtAGkIkDFGYDKLQCKLARDBxDcaF2hmHkEOU/ZSqwVlXXq2oT8AhwVqDNeOAZ93hRyHmA84AnVHV3yDmjK5PjBVREBRR8evevCAolhQfHUFyonWEYOUQRAMOATb5yg1vn5xXgXPf480AfERkYaDMLeDhQd5OrNvqZiHQjBBGZIyL1IlLf2NgYYbjGfkdQAPgjgRYjJ1dAARsAQLMrACwYnGFEIsp/SliC1WAase8C00XkZWA68DaQsfyJyFDgcOBJ3zXXAIcBRwMDgKvCPlxV56pqnarW1dbWhg6wkrKa7e90yHfZFhtAEL8AyKsCcjWZLXvs6d8w2kAUN9AGYISvPBzY7G+gqpuBcwBEpDdwrqpu9zX5IvCYqjb7rnnHPdwrIvfiCJE20717d95//30GDhyIWDJwZ3KVhBNeoWmX43LpJ1GVVcEEUFXe//Ajuqd3OmkaS8V7PnPRBxvhzeed4zAbQJBINgC3zYdvmf7fMNpAFAGwBBgrIqNxnuxnAX/vbyAig4BtqprGebK/J9DHbLfef81QVX1HnFn7bGAF+8Dw4cNpaGjA1EMuH77lPDXX9IaPP2jjxUr37esZ/refQFOJA9Ulqp1IoK//znkB9OifPT9kkhP2OYi/TfcDwvvuMcB53/Bn6DmoNOM1jBgQKSm8iMwEbgWSwD2qepOI3AjUq+oCETkPx/NHgWeBy1R1r3vtKOB5YIQrILw+/wTU4qiYlgFfV9WdhcYRlhTeCHCDO0me+H9h8Y/gkoXZp+IX74RVC2DgWDjz38s7rt6DoboHfPCmU67uDkOOyOrrm3Y78X56BU1HwJaVsHcHHDQFqkJWDek0vPMytDQ5AeT6jWjdxjBiTL6k8JF2AqvqQmBhoO463/F8INSdU1U30tpojKqeHOWzjX0k1eRM/KOOy9at+q3z3qMfHHxs54yr70Hh9TU9nVcYB44v3GciAcOOat+4DCOGmMK0qxIWa8czqEbRvRuG0eXpWrGA4o5fnZduCdlV65bDonBWAOm0cseitWzb3US/HjVcfvIhJBO5hv9XG7bzPy83cMLYWk46bHBoPy2pNHcsWkdLOs1lJx1C9+qs59Cmbbu5/4WNtKTzq0bPnjyMIQd055d/2UBzKp23XVv45IF9OP/oEfzi2fVs+ah1vCjD+MaJh1DbJ9Rbfp+pzJnACMfv3ZNqyr+rtkI9ZTa8v4t/e+oNqhJCS1qZMXEInxzSJ6fNr17YyPylDfztzQ/yCoC1jTv52dNvAHDCobUcPWpA5tyCVzZz93Mb6NOtKtQBeufeFj7Y1cSRB/dn7rPr6d2tivY6n+1tTiMCJ48bzI+feJ1uVQlqqirzNzI6ji9NO9gEgFGA4IarVpE1K/vnTrlP5WdMGsrjyzbTkm799O21KfQE35LS0GP/9cuuP63V6gLg5JsX05LWzHXPX3UyB/SMsJ+hAP/vydf5xZ/XZz77hjMnMHvqyHb1aRhRsMeMrkQw7HIrG0Bl6/7TrorLm5jDHNi8NgXm/5zrgl5w3vUhcz/gbK9QzbYrxWIqIUJaNTPmfJ9tGKXGBEBXwq8CSjeHpFds35NqZ+M9IVe7rqOpkFneq0sXkAAp36SfCgoA97p8mwoTIqTS6hMU7Z+tRYS0Fv9swyg1JgC6EsGQC/m8gCoUb66uSjoTZDpkCeBVhZ3z8J8Lyom0Eqr68Ugmcp/WkyWYrL0+PLVVKfo0jCiYAOhKBJOv582uVZl4E3dVwhMA+dsUEgCaIwBaq4AKqWAyT+ueCqgEc7X3eSnXpmGx7IxyYX9qXYlg8vVCsfUrEE+9U5V0/mzDJvmMCqiADcDvuRlUFaVUC6pgkgnnc73rSqECSrgSoDlVuj4NIwomALoSwcQr+VRAFTrBpIMqoJBZPt1OFZBqYRVM0GBbSF0UFW/CbzEBYJSZyvYLrHT2fAQ733MCnoXFwAFnRvpggxPvpu9Q2NWYzbHbox9o2ukHYNv63L6rA6EVKt4GkGsEDnvK1wgqoHQhFVA6mgoolVkBRBp6Qbw+mj0VkAkAo0yYAOhM5k53Ju1kN/inddCtT+s29b+E33+n7X1v/hscOiO3rqa3895/dNv72w/IqoDyG4E9r56QLQIZ0kVUQIlCRmBxrlFVRErjseOtIrwVQNLW5UaZMAHQmezY4jylN++GPdvDBcCOLc77iGmw6UXn+Kw7oKEelt7rlI+9HIZOdo6bd0FVdycxyoipuX2NOh5m/xpGVmZy+owKKJFfAJRCBVToCdyvAirVk7pkvIDSOWXD6GhMAHQm6WYnRn7z7lwDbrBNsgYGHpIVAJPOd1YNngAYcyKMPbX45yWr4JMzirfbT/HUO1kjcP42+6wCKuIFlHDdQFNF2rUFr5/MCsAEgFEmbLHZWag6njqenj6fAEg1O+6bSZ+sTlS1LscAT72TWQEU2AhWKEZbIQGQSmtBw25CHBWSIyhKM1FnVEDmBmqUGftT6yzSKefdi4GfLiAAktVZj55EtePF4/fwqXD3zqhEUwE5dYUSHeXYAFqtAAqrYDIqoHTpBID3eZ4bqKmAjHIRSQCIyAwRWS0ia0Xk6pDzB4vIMyKyXEQWi8hw37mUiCxzXwt89aNF5CURWSMivxaReMxiHt6u3epeueWwdsnq7CauTEhnn0dPhXv3RCUdQQXUZhtAYKWgRVQ7/p3ApVYBeasXUwEZ5aKoABCRJHAHcDowHpgtIsEUTTcD96vqJOBGnPSQHh+r6mT3daav/ifAz1R1LPAB8JV23Efl4T3xeyuAVHii9owNIBkQAMkYCgAvFpDrBRQWCyidUQFFEwDBWECptBacgEWElLsTuJC3UFtIZlYA5gZqlJcoK4CpwFpVXa+qTcAjwFmBNuOBZ9zjRSHnc3ATwZ9MNo3kr3ASw8cHb8LP2ADyrQDcoG7BJ3//pF/hIR6ikt185fzZhql5siqg4v2E9VFMBZQU55pSqoBabQQzxaxRJqL8qQ0DNvnKDbTO8fsKcK57/Hmgj4h4O5u6i0i9iLwoIt4kPxD4UFW9x96wPgEQkTnu9fWNjY0RhlsheBN+jasCKmgDqPHZANzsVTG0AaSCK4DQfQDkPRfsxznOPec82ecfQzYaaOlUQJ4cabGNYEaZiSIAwv4ag/9d3wWmi8jLwHTgbcCb3Ee62ej/HrhVRD4RsU+nUnWuqtapal1tbW2E4VYI3oRf1AvIswG4nj7exOb3/EnGwwso4wbakTuBtbgKyAsGV4owEOD3ArJQEEZ5iTJzNAAjfOXhwGZ/A1XdDJwDICK9gXNVdbvvHKq6XkQWA1OAR4F+IlLlrgJa9dnl8Sb8mmJG4IAXkEcMVwDB+DuFVED7nhCm8AScTLgqoCJB49pCUAVkO4GNchHlT20JMNb12qkBZgEL/A1EZJBIJjfSNcA9bn1/EenmtQGOA1aq81+3CDjPveZi4PH23kxFkYq4Akh7+wDyJHiH2NgAPLVOISOwp9IpmBAmRwXUOhZQoXk9owJKl14F5BmBzQ3UKBdFBYD7hH458CSwCpinqq+JyI0i4nn1nAisFpE3gAOBm9z6cUC9iLyCM+H/WFVXuueuAv5RRNbi2AR+WaJ7qgwyNoAIG8H8XkAeMfQC6pidwK3PFd4Ilt0JXCp3TVMBGZ1FJOWxqi4EFgbqrvMdzyfr0eNv81fg8Dx9rsfxMOoapFO5KRmL0bzbeff2ATTvhpa9rdu17IXq7q2f8mO8D6A6wkawqCqg8FAQBQRAQjI5gUutArJ9AEa5iYf1sKNJp+C2I2D7puJtg/To77z/9grnFcbYz0B1D7d9P+fdK0NsbACeeiezAigQCsI7H+arnypgBE6liwWDc65XLU0uAKfP3H0ANv8b5cIEQClo/tiZ/A85FQ4+Nvp1Nb1h/JmQuhN2vpu/3SGfhgFj4DM/cqKCAvQaBGf/HKq6Oa8Y4E3WycwKoHWb4NN9IsThrHA00MJuoElPBVQkb0BbaBUMrlQdG0YRTACUAk+ff8gpMO3Stl8/5YJo7Y69LLc8eXbbP6uC0YARuJAKyDkO7yfdDhWQiJQ8GFzGC8hsAEaZMYezUuDp/mMSlbOzyKiAEgVyAhdQ72TqA2qi3OuLq4DSrhtoyUJBZBLCeBvBStKtYRTFBEAp8FYAMdHFdxbZYHAFcgIXiPQZVh+qAooSDK4D3EAzKwCTAEaZMAFQCjwXThMAHUpGACS8UBD520D+gHCF9gGkisT4ERFSHaQCsmBwRrkxAVAKMgIgHu6YnUU2GmjxYHDOcXg/hXcCF8kJ7NsJXPKEMJYRzCgzJgBKQdoEQDkIhoIolBMY8ieFKbwRrLBqJycncIn+e4IqIJv/jXJhAqAUeDaAmIRk6CyCNoCwtI/pAuqdTH2BfADFwjx7oSCKqYraQtYLyEsJaRLAKA/mtlIKvNj+PhtASyrNT59czQe7mtjV1MKAXjVcdtIhDOnbndueWcPWnXv51imHUtunG79f/g6LV7/XSYOvHFZv2QFAtfvo/ftXN7O+cWdOmx17W1xPHbjhtyvpXtX6GWfVux8BzpP+n1a9x9Yd2R3YG7buYvxBffOOISHC7qYUr7/7EUMP6JG3XVvwVjRL3/zAKdsSwCgTJgBKQcYLKPt1bnx/N3OfXU/36gR7mp0nu2H9evL3U0dy69NrADh61ADOmjyMu/68ljVbdjKwlxmRi3HM6AH07VHNcYcMZEPjLp5fuzXnfG3vbpw6/kAWrX6PpRu35e3nuEMG0rOmitfe3p7TR7eqBNPGDMx73VEH9+fJ195FVfm7T+Rv1xYOHtiTQw/szc49LRwxoh/9e9lK0igPJgBKQbq1F5Cnrjht/BAWvOJEuk6l07nqh0z6Qjh+bC3/eXFdmQZc+Tz41WkFz9/AhA753DMmDeWMSUNL2ufgPt3545XTS9qnYUTBbAClwPMC8tkAgi6LwXrn2Hkv5ntuGIbREZgAKAUhbqDe071nsPQI24WaSpcuu5RhGEZUTAUUlXdfhYdnQ8sepzzqU/CF++A3l8EqNz+OTwXkPehXBdI7hcWhKaVPuWEYRlQirQBEZIaIrBaRtSJydcj5g0XkGRFZLiKLRWS4Wz9ZRF4Qkdfcc+f7rrlPRDaIyDL3Nbl0t9UBvLfKifg5ejr0HAQbnnPqNz4HvWrh+O/AoEMzzTMJzAuogDx7gKr5fhuGUX6KCgARSQJ3AKcD44HZIjI+0Oxm4H5VnQTcCPyrW78buEhVJwAzcJLC9/Nd9z1Vney+lrXzXjoWz9PnlOtgzPSs2kcVRhzj1Pu8gLI+67lfcU68evcwVcIE44ZhGFGJsgKYCqxV1fWq2gQ8ApwVaDMeeMY9XuSdV9U3VHWNe7wZeA+oLcXAy44/4FuyOlvWFEjrr9Gb3ING4LAwBKYCMgyjM4giAIYB/lRXDW6dn1eAc93jzwN9RCTHSVpEpgI1wDpf9U2uauhnXvL4ICIyR0TqRaS+sbExwnA7iMxmr2rH28dz/UynQmMCBHetBushuxpIF8lCZRiG0RFEEQBhM1Nwj/13geki8jIwHXgbyCTIFZGhwAPAl1XV28B/DXAYcDQwACdJfOsPUp2rqnWqWldb24mLh8wKoNpZBaRbnMd5TYEkWzX3PHyqfMJBNRiv3ns3N1DDMMpPFC+gBmCErzwc2Oxv4Kp3zgEQkd7Auaq63S33BX4PXKuqL/quecc93Csi9+IIkf2XtM/X39P1p5rdFUCIAAhRASm5AcpMBWQYRmcSZQWwBBgrIqNFpAaYBSzwNxCRQSIZRfg1wD1ufQ3wGI6B+L8D1wx13wU4G1jRnhvpcPwx/z13z1QTaDqPDaC1EdgJIkZO2Xm3AGCGYZSfogJAVVuAy4EngVXAPFV9TURuFJEz3WYnAqtF5A3gQOAmt/6LwAnAJSHung+KyKvAq8Ag4IeluqkOIbPbN5nd8ZtudgVA2AogN38tZOPIZ9tk623+Nwyj3ETaCKaqC4GFgbrrfMfzgfkh1/0X8F95+jy5TSPtbFJNzpO/SHbHbwEVkPd073fvTGswFISpgAzD6DwsFERU0i1Z1U9GBdSc1w00bCdwys0lm+nSQkEYhtGJmACISqoJEu6CKbMCcG0AoUbg1juB03lVQLYT2DCM8mMCICqp5tYrgHSLowIKWQFkg8HluoGGhYJIq1oSEMMwyo4JgKikmrNP/t5KINWUfx+AO8/7jcCpdO4KwHMDTRVJRG4YhtERxDMaaPMemPcl2P0+fHImrHnKmcy79YbjvgV//mnW68fjg43QrY9z7K0A/vvLznsBN9BkKxVQtk1mJ7CpgAzD6ATiKQC2b4I1f3SO317qvA85HDY8C9W9YNNLMOak7JM+QM+BMOZE53h4HYw70wkRDdkQ0T6yCWECKqCQYHBqKiDDMDqBeAqA4NM9wEn/DA/PguZdTnn2I1DdPfz63oPh/AfgL7fC09c7aqAA+VRAqTAVUNrcQA3DKD/xtAF4cX38VPd03pt2O+/JCIm5Pe8ff4hPl3SIETitmtPUrwIyG4BhGOUmngIg3dK6rqaX896829Hph7h2tsLT/afDVgCtcwK33giWXQXY/G8YRrmJpwAIXQH0cN6bduUkdy+I5/0TogLKuIH6BUBaAwlhsmVTARmGUW5iKgACNgBJQpWr72/enZPbtyDeKiFkBRC2EzioAvJ7BdlOYMMwyo0JAHCTvLj28KZdOakdC+KpgDTd6lRYMLiUtl4BeO1sAWAYRrmJqQBwVUCe4dcf4rktK4CMAAhRAeVzA83JCObbL2ASwDCMMhNPAeAld/EEQKIq1+snqg0gowIKWwE47/6UkMGNYOormw3AMIxyE08B4KmAavwrAN+kH8UFFAoagdMhRuBgKIiUzyhs879hGOUm3gKg2nX99BK9e0QVAAWMwFkbQH4VkN8N1IzAhmGUm0gCQERmiMhqEVkrIleHnD9YRJ4RkeUislhEhvvOXSwia9zXxb76o0TkVbfP293UkOXBs3JgO+sAABQ6SURBVAFkVgDVuXr/NtsATAVkGEblUVQAiEgSuAM4HRgPzBaR8YFmN+Pk/Z0E3Aj8q3vtAOB64BhgKnC9iPR3r7kLmAOMdV8z2n03UWllA6jO3fiVaKsXUCEVUG5OYH8sIL9XkO0ENgyj3ESZ6aYCa1V1PYCIPAKcBaz0tRkPXOkeLwJ+4x5/BnhKVbe51z4FzBCRxUBfVX3Brb8fJzH8E+26m2K8+HN483nYtsEp1/hUQCLOk3+qia0fK9//LydIXFUywcmH1fLUyi0ZH34RuPjYURypCaqBv218n7vd9h7rG52YQn4bwLJNH/LuR07guITA/27YxlWPLs+UDcMwykkUATAM2OQrN+A80ft5BTgXuA34PNBHRAbmuXaY+2oIqW+FiMzBWSkwcuTICMMtwPO3OcHe+hwEY0+DCefAB2/CYWc45yecA++8wuMfTeK5NVsZ3Lcb6xt3sfDVd1BVDhncG4B1jbs4oEc1A44+lm3pw7il6Qt80Liz1cd9etxg+vao5rTxB/LUqi3061nNnuYU08YM4LAhffnruq00fLCbCQf15Yjh/dp3b4ZhGG0kigAIezYNRj/7LvAfInIJ8CzwNtBS4NoofTqVqnOBuQB1dXWhbSKTaoKJ58Jnf5atO+L87PE5vwDgoX9bzPSD+3LT2ROZfONTpNJKv57V/PHK6QBM+9EzpNOQqu7F+U3XcdcXjuT0w4fm/di5F9W1a9iGYRgdQRQB0ACM8JWHA5v9DVR1M3AOgIj0Bs5V1e0i0gCcGLh2sdvn8EB9Tp8dQro5koFX1THK+u3SiZxj16Dr2n7Lab82DMMoFVG8gJYAY0VktIjUALOABf4GIjJIJJMW6xrgHvf4SeA0EenvGn9PA55U1XeAHSIyzfX+uQh4vAT3U5hUcyQDb0qVpOS6ZuYIgISQ8oVxMBdOwzAqkaICQFVbgMtxJvNVwDxVfU1EbhSRM91mJwKrReQN4EDgJvfabcC/4AiRJcCNnkEYuBT4T2AtsI6ONgBDbmL3AqTVSdDin9dzjyXHp9/mf8MwKpFI/o6quhBYGKi7znc8H5if59p7yK4I/PX1wMS2DLZdqLoqoOKbvNJpR62TKKICslDOhmFUMvHZCewlgYkiAFRJJnIn9hx1UELcsA7ZsmEYRqURHwHg7f6NEOgtTAUkISogy+ZlGEYlEyMB4O7+jWADSEVQAfkDuZkKyDCMSiSGAqD4CkA9FVAijwpIJCeujwkAwzAqkfgIgHR0AeCpgCCr3gmqgNLmBWQYRoUTHwHQBhtAKp0VAN6TfzJgEE7bPgDDMCqcGAkAzwso+k5gyO7yDd0JnAkOZwLAMIzKI2Lc4wpn6a/grRed4wgJ3x0VkHMcpgISTwWUNhWQYRiVSzwEwNqnYd2foOcgGHRo0eYp1Vaqn2TAIJxOmwrIMIzKJh4C4PwH2tQ8ra1VP7YT2DCMrkZ8bABtQH0qIAmogpw6CdgAyjs+wzCMUmACIIRU2qcCct9z9gSIkE5bQnfDMCobEwAhFFUBJVwVkJoKyDCMysUEQICgZ48ENoQ5x14+AFqdMwzDqBRMAATIePZkvH+c+mBcoFw3UJMAhmFUHiYAAgRDPOfzAlLfTmATAIZhVCKRBICIzBCR1SKyVkSuDjk/UkQWicjLIrJcRGa69ReIyDLfKy0ik91zi90+vXODS3tr+4Y3qWe9fzwjcLZNQgL5AEwAGIZRgRTdByAiSeAO4FScZO5LRGSBqq70NbsWJ1XkXSIyHid72ChVfRB40O3ncOBxVV3mu+4CNzPYfkNQBZQIUwElAiogW0cZhlGBRJm6pgJrVXW9qjYBjwBnBdoo0Nc9PgDYHNLPbODhfR1ouQg+1ZsKyDCMrkoUATAM2OQrN7h1fm4ALhSRBpyn/2+G9HM+rQXAva765/uSJ6KaiMwRkXoRqW9sbIww3PaR2d1bJBSEXwVk+wAMw6hEogiAsNlNA+XZwH2qOhyYCTwgIpm+ReQYYLeqrvBdc4GqHg4c776+FPbhqjpXVetUta62tjbCcNtHMM1joZ3AqYC9wDAMo5KIIgAagBG+8nBaq3i+AswDUNUXgO7AIN/5WQSe/lX1bfd9B/AQjqqp08mnApKAG2huTmCTAIZhVB5RBMASYKyIjBaRGpzJfEGgzVvAKQAiMg5HADS65QTwBRzbAW5dlYgMco+rgc8CK9gPaKUCCksII07EUK9t0gSAYRgVSFEvIFVtEZHLgSeBJHCPqr4mIjcC9aq6APgOcLeIXImjHrpEvcdjOAFoUNX1vm67AU+6k38SeBq4u2R31Q5aq4DC3UAtJ7BhGJVOpHDQqroQx7jrr7vOd7wSOC7PtYuBaYG6XcBRbRxrWWitAnLKfhWQBILBibmBGoZRgdjUFSDVKhREWE7g3HwApgIyDKMSiUVCmH/742qWbfoQcJ7sLz/5EA4b0oerHl3Ojj1OruDn1mzl+LGD2NucBrKePd7UHgwG9/7OJh5ZsilTNgzDqDRiIQA+bkqxc68z0S/b9CGHDemDAAtffZdP1Pbi46aUc+6tDznkwN4cM3oAU0b2B+BzRxxEIiGcOn5Ipr9Txh3IG1t2oMDZkw+ie7UtpAzDqDxiIQCu/ez4zPH46/6QY8C98ayJvNLwIT/9w2pOHjeY22ZNybn2q8eP4avHj8mpO3X8gZw6/sAOH7dhGEZHErtHVyeQW9bdU8RUOIZhxJMYCgDHgKs+Y68ZcQ3DiCPxEwAJcQO5Zcs2/xuGEUfiJwDcdI4p34YvUwEZhhFHYikA0kpOKGeL5mkYRhyJoQBwdvD6A7nZ/G8YRhyJnQDwYvmn0tlywiSAYRgxJHYCIKgCMjdQwzDiSuwEgATcQE0FZBhGXImdAEgmhHRQBWQrAMMwYkjsBEBrLyBTARmGEU8iCQARmSEiq0VkrYhcHXJ+pIgsEpGXRWS5iMx060eJyMdu4vdlIvJz3zVHicirbp+350sKX2o8FVDWBiA5yV4MwzDiQtGpT0SSwB3A6cB4YLaIjA80uxaYp6pTcFJG3uk7t05VJ7uvr/vq7wLmAGPd14x9v43oJDPZvLKhICQ0771hGEbXJsqz71RgraquV9UmnNy+ZwXaKNDXPT6A1knjcxCRoUBfVX3BTR15P3B2m0a+jyTcbF7pdLZsGIYRR6IIgGHAJl+5wa3zcwNwoYg04KSO/Kbv3GhXNfRnETne12dDkT4BEJE5IlIvIvWNjY0RhlsY8RK6+9xADcMw4kgUARA2RWqgPBu4T1WHAzOBB0QkAbwDjHRVQ/8IPCQifSP26VSqzlXVOlWtq62tjTDcwiTdYHCZaKDmA2oYRkyJkhCmARjhKw+ntYrnK7g6fFV9QUS6A4NU9T1gr1u/VETWAYe6fQ4v0meHkPUCypYNwzDiSJQVwBJgrIiMFpEaHCPvgkCbt4BTAERkHNAdaBSRWteIjIiMwTH2rlfVd4AdIjLN9f65CHi8JHdUhEQmFITrBmoeQIZhxJSiKwBVbRGRy4EngSRwj6q+JiI3AvWqugD4DnC3iFyJo8q5RFVVRE4AbhSRFiAFfF1Vt7ldXwrcB/QAnnBfHU4wIYytAAzDiCuRcgKr6kIc466/7jrf8UrguJDrHgUezdNnPTCxLYMtBQkRVLMpIU0AGIYRV2KnAEmKowLybACWDtIwjLgSOwHQaidw7L4BwzAMh9hNf54KKG02AMMwYk7sBEAy4eQENhWQYRhxJ3YCoHUwuE4ekGEYRicROwHgxAJS0uYFZBhGzImdAEgmcncCWygIwzDiSuwEQCKgArL53zCMuBI7ASDePoC0IuKUDcMw4kjsBEAy4wZq+n/DMOJN7ARAIgEb39/Ffyxam6nz5IAJBMMw4kTsBMCZRwxjWP8eQDYe0OkTh3LhtJFce8a4zhyaYRhGWYmdAJgxcQhfmnZwTl1NVYIfnn04A3t366RRGYZhlJ/YCQAw10/DMAyIqQAwzx/DMIyYCgBbABiGYUQUACIyQ0RWi8haEbk65PxIEVkkIi+LyHIRmenWnyoiS0XkVff9ZN81i90+l7mvwaW7rcJYADjDMIwIGcHcnL53AKfiJHNfIiIL3CxgHtcC81T1LhEZj5M9bBSwFficqm4WkYk4aSWH+a67wM0MVlbM3dMwDCPaCmAqsFZV16tqE/AIcFagjQJ93eMDgM0Aqvqyqm52618DuotIp7va2PxvGIYRTQAMAzb5yg3kPsUD3ABcKCINOE//3wzp51zgZVXd66u711X/fF/yWGZFZI6I1ItIfWNjY4ThFse8gAzDMKIJgLDZUgPl2cB9qjocmAk8IJJNtigiE4CfAP/gu+YCVT0cON59fSnsw1V1rqrWqWpdbW1thOEWx1RAhmEY0QRAAzDCVx6Oq+Lx8RVgHoCqvgB0BwYBiMhw4DHgIlVd512gqm+77zuAh3BUTWXB5n/DMIxoAmAJMFZERotIDTALWBBo8xZwCoCIjMMRAI0i0g/4PXCNqj7vNRaRKhHxBEQ18FlgRXtvJiqmAjIMw4ggAFS1Bbgcx4NnFY63z2sicqOInOk2+w7wNRF5BXgYuERV1b3uEOD7AXfPbsCTIrIcWAa8Ddxd6pvLh6mADMMwIriBAqjqQhzjrr/uOt/xSuC4kOt+CPwwT7dHRR9mabEFgGEYRmx3ApsEMAzDMAFgGIYRU2IpAMwIbBiGEVMBYAsAwzCMmAoAUwEZhmHEVACYCsgwDCOmAsAWAIZhGDEVAKYCMgzDiKkAMBWQYRhGTAWAzf+GYRgxFQCWFN4wDCOmAsByAhuGYcRUAJgR2DAMI64CIJZ3bRiGkUssp0JbARiGYZgAMAzDiC2RBICIzBCR1SKyVkSuDjk/UkQWicjLIrJcRGb6zl3jXrdaRD4Ttc+OJBlLsWcYhpFL0alQRJLAHcDpwHhgtoiMDzS7FidV5BScnMF3uteOd8sTgBnAnSKSjNhnh2FuoIZhGNFWAFOBtaq6XlWbgEeAswJtFOjrHh8AbHaPzwIeUdW9qroBWOv2F6XPDsNTAR3Qo7pcH2kYhrHfESUn8DBgk6/cABwTaHMD8EcR+SbQC/i079oXA9cOc4+L9QmAiMwB5gCMHDkywnCLM6J/D7407WBOHje4JP0ZhmFUIlFWAGH6Eg2UZwP3qepwYCbwgIgkClwbpU+nUnWuqtapal1tbW2E4RanKpngX86eyEmfNAFgGEZ8ibICaABG+MrDyap4PL6Co+NHVV8Qke7AoCLXFuvTMAzD6ECirACWAGNFZLSI1OAYdRcE2rwFnAIgIuOA7kCj226WiHQTkdHAWOB/I/ZpGIZhdCBFVwCq2iIilwNPAkngHlV9TURuBOpVdQHwHeBuEbkSR5Vziaoq8JqIzANWAi3AZaqaAgjrswPuzzAMw8iDOPN0ZVBXV6f19fWdPQzDMIyKQkSWqmpdsN62RBmGYcQUEwCGYRgxxQSAYRhGTDEBYBiGEVMqyggsIo3Am/t4+SBgawmHUwnYPccDu+d40J57PlhVW+2krSgB0B5EpD7MCt6VsXuOB3bP8aAj7tlUQIZhGDHFBIBhGEZMiZMAmNvZA+gE7J7jgd1zPCj5PcfGBmAYhmHkEqcVgGEYhuHDBIBhGEZMiYUA6MwE9B2FiIwQkUUiskpEXhORb7n1A0TkKRFZ4773d+tFRG53v4PlInJk597BvuPmlX5ZRH7nlkeLyEvuPf/aDTGOG4b81+49vyQiozpz3PuKiPQTkfki8rr7ex/b1X9nEbnS/bteISIPi0j3rvY7i8g9IvKeiKzw1bX5dxWRi932a0Tk4raMocsLgM5OQN+BtADfUdVxwDTgMve+rgaeUdWxwDNuGZz7H+u+5gB3lX/IJeNbwCpf+SfAz9x7/gAnQRHu+weqegjwM7ddJXIb8AdVPQw4Aufeu+zvLCLDgCuAOlWdiBMyfhZd73e+DzeRlo82/a4iMgC4Hiel7lTgek9oREJVu/QLOBZ40le+Brims8fVAff5OHAqsBoY6tYNBVa7x78AZvvaZ9pV0gsne9wzwMnA73DSi24FqoK/N06+iWPd4yq3nXT2PbTxfvsCG4Lj7sq/M9k85APc3+13wGe64u8MjAJW7OvvipOO9xe++px2xV5dfgVAeFL7YXnaViTukncK8BJwoKq+A+C+e4mPu8r3cCvwT0DaLQ8EPlTVFrfsv6/MPbvnt7vtK4kxONn17nXVXv8pIr3owr+zqr4N3IyTafAdnN9tKV37d/Zo6+/art87DgIgcgL6SkREegOPAt9W1Y8KNQ2pq6jvQUQ+C7ynqkv91SFNNcK5SqEKOBK4S1WnALvIqgXCqPh7dlUYZwGjgYOAXjgqkCBd6XcuRr57bNe9x0EARElqX5GISDXO5P+gqv6PW71FRIa654cC77n1XeF7OA44U0Q2Ao/gqIFuBfqJiJfe1H9fmXt2zx8AbCvngEtAA9Cgqi+55fk4AqEr/86fBjaoaqOqNgP/A/wdXft39mjr79qu3zsOAqBLJqAXEQF+CaxS1Vt8pxYAnifAxTi2Aa/+ItebYBqw3VtqVgqqeo2qDlfVUTi/459U9QJgEXCe2yx4z953cZ7bvqKeDFX1XWCTiHzSrToFJ8d2l/2dcVQ/00Skp/t37t1zl/2dfbT1d30SOE1E+rsrp9Pcumh0thGkTIaWmcAbwDrgnzt7PCW6p0/hLPWWA8vc10wc3eczwBr3fYDbXnC8odYBr+J4WHT6fbTj/k8EfucejwH+F1gL/DfQza3v7pbXuufHdPa49/FeJwP17m/9G6B/V/+dgR8ArwMrgAeAbl3tdwYexrFxNOM8yX9lX35X4P+4974W+HJbxmChIAzDMGJKHFRAhmEYRggmAAzDMGKKCQDDMIyYYgLAMAwjppgAMAzDiCkmAAzDMGKKCQDDMIyY8v8BlYzHkCKRrdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['val_acc'], label='validation')\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode = 'min')\n",
    "mc = ModelCheckpoint('/Users/rsruti/Documents/Projects/Py-Scripts/EarlyStopping.model', monitor='val_accuracy', mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "# simple early stopping\n",
    "\n",
    "# fit model\n",
    "#history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(500, activation='relu',input_dim = 2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2756 - acc: 0.8429 - val_loss: 0.4450 - val_acc: 0.7667\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.2733 - acc: 0.8571 - val_loss: 0.4432 - val_acc: 0.7667\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.2709 - acc: 0.8571 - val_loss: 0.4373 - val_acc: 0.7667\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2682 - acc: 0.8571 - val_loss: 0.4304 - val_acc: 0.7667\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.2659 - acc: 0.8714 - val_loss: 0.4227 - val_acc: 0.7667\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 108us/step - loss: 0.2636 - acc: 0.8714 - val_loss: 0.4136 - val_acc: 0.7667\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.2614 - acc: 0.8571 - val_loss: 0.4038 - val_acc: 0.8000\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2606 - acc: 0.8571 - val_loss: 0.3945 - val_acc: 0.8000\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.2595 - acc: 0.8571 - val_loss: 0.3903 - val_acc: 0.8333\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.2582 - acc: 0.8571 - val_loss: 0.3899 - val_acc: 0.8333\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 99us/step - loss: 0.2560 - acc: 0.8429 - val_loss: 0.3933 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=32, epochs = 1000, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXgd9X3v8fdX+25ttiRLtiWwWbzFhoOhIWVLIDYkhrY0dQppyJPUNzS+ZLnpjdMmvQlNntvSPITmKTepk0Jue1lKIBSHBEwAG0ISiOXi2paMwRtYljfJuy1Z2/f+MSN5JB9Jx7YWW+fzep7znJnfzPz0G+LM58z8Zn5j7o6IiCSflNFugIiIjA4FgIhIklIAiIgkKQWAiEiSUgCIiCSptNFuwOkoLS316urq0W6GiMh5Zc2aNU3uPr5v+XkVANXV1dTW1o52M0REzitm9m688oQuAZnZfDPbZGabzWzpAOvdbmZuZrFwvtrMWsxsbfj5QWTdy81sfVjn98zMTnenRETkzA16BmBmqcCDwI1AA7DazJa7e32f9fKBe4A3+lSxxd3nxKn6+8Bi4HXgF8B84LnT3gMRETkjiZwBzAM2u/tWd28DHgdujbPe3wL3Aa2DVWhmFUCBu//Wg0eR/xW4LfFmi4jI2UqkD6AS2BGZbwCujK5gZnOBSe7+rJl9uc/2NWb2JnAY+Jq7/yqss6FPnZXx/riZLSY4U2Dy5MkJNFdEzgft7e00NDTQ2jrob0ZJUFZWFlVVVaSnpye0fiIBEO/afM8AQmaWAnwXuCvOeruAye7ebGaXA/9hZjMGq7NXofsyYBlALBbTwEUiY0RDQwP5+flUV1ejLsCz5+40NzfT0NBATU1NQtskcgmoAZgUma8CGiPz+cBMYJWZbQeuApabWczdT7h7c9i4NcAW4KKwzqoB6hSRMa61tZWSkhId/IeImVFSUnJaZ1SJBMBqYJqZ1ZhZBrAIWN690N0PuXupu1e7ezVBp+5Cd681s/FhJzJmdgEwDdjq7ruAI2Z2VXj3z58BzyTcahEZE3TwH1qn+99z0EtA7t5hZkuAFUAq8JC715nZvUCtuy8fYPNrgHvNrAPoBD7r7vvDZXcDPwayCe7+GbY7gH76nw3sPNBCQXY6+VlpFGQF3/lZ6RRkB9/5mWmkpOgfo4gkj4QeBHP3XxDcqhkt+5t+1r0uMv0U8FQ/69USXDoads+u28XLb+0dcB0zyMtIOyUkuudPlp0MjYJIiBRkpZOZlqJfNCJjWF5eHkePHqWxsZF77rmHJ5988pR1rrvuOr7zne8Qi8X6reeBBx5g8eLF5OTkAHDzzTfz6KOPUlhYOGxtj+e8ehL4TD101xW0dXRxpLWdI60dHO7+bjk5f7i1gyOt7RxuCb9b29l9uJW39x7pWbdrkC7ojNSUU0KjMCeD6RUFzKocx+yqcRTmZIzMTovIsJk4cWLcg3+iHnjgAe68886eAPjFL34xyBbDIykCACAjLYWSvExK8jLPaHt353hbZ7/hEZ0/ubydHfsP8fN1u3rqmVycw+yqIAxmVRYys7KA/KzEbtkSkaH1la98hSlTpvAXf/EXAHzjG9/AzHj11Vc5cOAA7e3tfOtb3+LWW3s/+rR9+3Y+8pGPsGHDBlpaWvjUpz5FfX09l156KS0tLT3r3X333axevZqWlhZuv/12vvnNb/K9732PxsZGrr/+ekpLS1m5cmXPMDelpaXcf//9PPTQQwB85jOf4Qtf+ALbt29nwYIFfOADH+A3v/kNlZWVPPPMM2RnZ5/V/idNAJwtMyM3M43czDQqxp3etoda2tmw8xDrGg6xfudB3nzvIM+GoWAGF5TmMruqsCcYpleMIzsjdRj2QuTc9M2f1VHfeHhI65w+sYD/9dEZA66zaNEivvCFL/QEwBNPPMHzzz/PF7/4RQoKCmhqauKqq65i4cKF/V7e/f73v09OTg7r1q1j3bp1XHbZZT3Lvv3tb1NcXExnZycf/OAHWbduHffccw/3338/K1eupLS0tFdda9as4eGHH+aNN97A3bnyyiu59tprKSoq4p133uGxxx7jhz/8IR/72Md46qmnuPPOO8/qv5ECYASMy07n6qmlXD315P/YzUdPsG7nIdY3BMHw681NPP3mTgBSU4xpE/LCQAiC4ZLyAjLSNHq3yFCaO3cue/fupbGxkX379lFUVERFRQVf/OIXefXVV0lJSWHnzp3s2bOH8vLyuHW8+uqr3HPPPQDMnj2b2bNn9yx74oknWLZsGR0dHezatYv6+vpey/t67bXX+IM/+ANyc3MB+MM//EN+9atfsXDhQmpqapgzJxhV5/LLL2f79u1nvf8KgFFSkpfJ9RdP4PqLJ/SU7TncyrqGQ6xrOMi6hkP8sn4PT9QGD0xnpKZwSUU+syrH8b6qQmZVjWPahDzSUhUKcv4b7Jf6cLr99tt58skn2b17N4sWLeKRRx5h3759rFmzhvT0dKqrqwe9tz7e2cG2bdv4zne+w+rVqykqKuKuu+4atJ5gZJz4MjNPXr5OTU3tdanpTCkAziFlBVncOD2LG6eXAcE/hoYDLazfeYj/ajjI+oZDLF/byCNvvAdAVnoKMyaOC0JhUtCncEFprm5nFTkNixYt4s///M9pamrilVde4YknnmDChAmkp6ezcuVK3n037kjKPa655hoeeeQRrr/+ejZs2MC6desAOHz4MLm5uYwbN449e/bw3HPPcd111wGQn5/PkSNHTrkEdM0113DXXXexdOlS3J2nn36af/u3fxuW/QYFwDnNzJhUnMOk4hxunlUBQFeXs735WBAKO4I+hX9fvYMf/2Y7AHmZacysLGB2VSFzJxVyeXURE/KzRnEvRM5tM2bM4MiRI1RWVlJRUcEdd9zBRz/6UWKxGHPmzOGSSy4ZcPu7776bT33qU8yePZs5c+Ywb948AN73vvcxd+5cZsyYwQUXXMDVV1/ds83ixYtZsGABFRUVrFy5sqf8sssu46677uqp4zOf+Qxz584dkss98dhApxznmlgs5nohzKk6OrvYsu9Yz6WjdTsPsbHxMG2dXQBUl+QQqy5mXnUxseoiakpz9byCjLqNGzdy6aWXjnYzxpx4/13NbI27n/Jggs4AxoC01BQuLs/n4vJ8/jgWDNvU1tHFhsZD1G7fz+rtB3hp4x6eXBP0J5TkZhCrLuKK6mKuqC5m+sQC0tWXIJJ0FABjVEZaCpdNLuKyyUUsviboT9iy7xi12/fzu+37qd1+gBV1ewDITk9l7uRCYtXFXFFdxNzJReRl6p+GyFin/5cnCTNj6oQ8pk7IY9G84L0Kew63Urv9AKu372f19v3808vv0OXBbajTKwp6zhJi6kcQGZMUAEmsrCCLW2ZXcMvsoIP5SGs7b753sOey0WO/e4+Hf70dgCklOcSmFDOvpohYdTEXqB9B5LynAJAe+VnpXHPReK65aDwA7Z1dbNh5qOcsYeWmvTz1n0E/QnFuBrEpYT9CTTEz1I8gct5RAEi/0lNTmDs56BP482suwN3Z2nSs5wxh9fb9vFAf9CNkpacwd1IRV1QXcUVNMbEpxRrOQuQcpwCQhJkZF47P48LxefzJFUE/wt7DrdS+G4RB7fYD/NPKzXS9HDy5HKsu4uqppXxgaikzK8eRqgfU5Bxy8OBBHn300Z5xgBI1WkM3Dwc9ByBD6uiJDmq37+fXm5t4bXMzG3cFA3yNy07n/ReW9ATClJIc9SEkudF+DiA6omdUZ2cnqann79mrngOQUZOXmcZ1F0/gunCMo6ajJ/jNlmZee2cfr73TxHMbdgNQWZjN708LBsh7/4UlZzxMt8iZWrp0KVu2bGHOnDmkp6eTl5dHRUUFa9eupb6+nttuu40dO3bQ2trK5z//eRYvXgzQM3Tz0aNHh2WI5pGU0BmAmc0H/pHglZA/cve/62e924GfAFeE7wS+Efg7IANoA/7S3V8O110FVADdIxrd5O4DvrZLZwDnN3dne/PxIAw2N/GbLc0cae0AYHpFQU8gXFGt/oNk0OuX6nNLYff6of0D5bNgQdxDFdD7DGDVqlXccsstbNiwgZqaGgD2799PcXExLS0tXHHFFbzyyiuUlJT0CoCpU6dSW1vLnDlz+NjHPsbChQvPeojmszWkZwDhS90fBG4EGoDVZrbc3ev7rJcP3AO8ESluAj7q7o1mNpPgvcKVkeV3hK+GlCRgZtSU5lJTmssnfq+ajs4uNjQe7gmEh369jX9+dSsZqSlcPqWID0xT/4GMnHnz5vUc/AG+973v8fTTTwOwY8cO3nnnHUpKSnptMxxDNI+kRC4BzQM2u/tWADN7HLgVqO+z3t8C9wFf7i5w9zcjy+uALDPLdPcTZ9VqGRPSUlOYM6mQOZMKWXLDNI63dbB6+4EwEJr5hxWb+IcVmyjISuP9F5b2BIL6D8agAX6pj5TuMfgBVq1axYsvvshvf/tbcnJyuO666+IO5TwcQzSPpEQCoBLYEZlvAK6MrmBmc4FJ7v6smX2Z+P4IeLPPwf9hM+skeHH8tzzO9SgzWwwsBpg8eXICzZXzVU5GGtdeNJ5rw+cQ+vYfPF93sv/gA1ODQFD/gZyp7iGZ4zl06BBFRUXk5OTw1ltv8frrr49w60ZGIgEQ76dWz4HazFKA7wJ39VuB2Qzg74GbIsV3uPvO8NLRU8AngH895Q+5LwOWQdAHkEB7ZYwozctk4fsmsvB9E0/pP/jFhl38e23wu2R6RUHP2cG8mmKy0tV/IIMrKSnh6quvZubMmWRnZ1NWVtazbP78+fzgBz9g9uzZXHzxxVx11VWj2NLhM2gnsJn9HvANd/9wOP9VAHf/3+H8OGALcDTcpBzYDywMO4KrgJeBT7n7r/v5G3cBMXdfMlBb1Aks3fr2H6x59wDtnU5ORirXXjSem2aUccPFZYzLSR/tpko/Rvs20LFqqG8DXQ1MM7MaYCewCPjT7oXufgjoea1NeHfPl8ODfyHwc+Cr0YO/maUBhe7eZGbpwEeAFxPfRUl28foP3ti2nxfr9/DL+j08t2E3aSnGVReUcNOMMm6cXkbFuPPn9jyRkTBoALh7h5ktIbiDJxV4yN3rzOxeoNbdlw+w+RJgKvB1M/t6WHYTcAxYER78UwkO/j88i/2QJJeTkdbzjuW/vXUm/9VwkBfq9/BC3W7+5pk6/uaZOmZXjeOm6WXcNKOcaRPy1JEsSU9PAsuYt3nvUX5Zv4cVdbtZu+MgELwl7aYZ5Xx4RhlzJhXpNtNRsHHjRi655BIF8RByd956662ELwEpACSp7Dncyi/r9/BC/R5+u6WJ9k6nNC+TG6dP4Kbp5fzehSXqRB4h27ZtIz8/n5KSEoXAEHB3mpubOXLkSK/nGUABIHKKw63trNq0jxfqdrNq0z6OnuggNyOV6y6ewE0zyrj+kgkUZKkTebi0t7fT0NAQ9/56OTNZWVlUVVWRnt77360CQGQAJzo6+e2WZlbUBZ3ITUdPkJ7a3Ylczo2XllE+Tm9Fk/OTAkAkQV1dzps7DvJC/W5eqNvDtqZjALxvUiE3TS/jwzPKmDohf5RbKZI4BYDIGXB3tuw7yoq6oN/gv8JO5AvG53LT9HJumlHGnKpCUtSJLOcwBYDIENh1qIUXezqRm+nocsbnZ3LT9DJumVXBvJpi0vRqTDnHKABEhtihlnZWbdrLirAT+XhbJ6V5GXx4Rjm3zK7gypoS3V4q5wQFgMgwamnrZNWmvTy7fhcvb9xLS3snpXmZLJhZzs3hmYHCQEaLAkBkhBxv62DVpn38fN0uXnprD63tXZTmZXLzrHJumVVBrFphICNLASAyCo63dfDyW3v5+bpdrNy0l9b2LibkB2cGt8yeSGxKkTqQZdgpAERG2bETvcPgREcXZQWZLJhZwS2zK7h8ssJAhocCQOQccuxEBy+9tZefr2tk5aZ9tIVhcPOsCm6ZVcFlCgMZQgoAkXPU0RMdvLRxDz9ft4tVbwdhUF6QFYTB7ArmTtJzBnJ2FAAi54Ejre28tHEvz67bxatv76Ots4uJ47JYEAkDDZwmp0sBIHKeOdza3nNm8OrbTbR1dlFZmB12IFcwR2EgCVIAiJzHDre282J9GAbv7KO906kszObmWeUsmFWh4ShkQAoAkTHiUEs7v6zfwy/W7+JXYRiUF2Tx4RllzJ9ZwRXVRRqOQno5qwAws/nAPxK8vvFH7v53/ax3O/AT4Ap3rw3Lvgp8GugE7nH3FadTZ5QCQKS3Qy3tvPzWHp5bv5tX3t7HiY4uinMzuPHSMubPKuf9F5aQmaYX3CS7Mw4AM0sF3gZuBBoIXhL/cXev77NePsEL4DOAJeFL4acDjwHzgIkE7/69KNxk0Dr7UgCI9O94WwevbNrHcxt28/Jbezl6ooP8zDRuuHQCC2aWc81F48nJGPQ14DIG9RcAifxrmAdsdvetYUWPA7cCfQ/WfwvcB3w5UnYr8Li7nwC2mdnmsD4SrFNEEpSTkcaCWRUsmFXBiY5Ofr25iec37OaX9Xt4Zm0jWekpXHfRBObPLOeGS/W2M0ksACqBHZH5BuDK6ApmNheY5O7PmtmX+2z7ep9tK8PpAeuM1L0YWAwwefLkBJorIplpqdxwSRk3XFJGR2cXv9u2n+frdvP8ht08X7eb9FTj6qmlzJ9Rzo3TyyjJyxztJssoSCQA4t1a0HPdyMxSgO8Cd53GtvF6qOJei3L3ZcAyCC4BDdJWEekjLTWF908t5f1TS/nGR2fw5o6DrKjbzXMbdrH0p+v5q6fXM6+mmPkzyvnwzHIqxmWPdpNlhCQSAA3ApMh8FdAYmc8HZgKrwnuSy4HlZrZwkG0HqlNEhkFKinH5lCIun1LEVxdcQv2uw8FZwYbdfONn9XzjZ/XMmVTI/JnlLJhZzpSS3NFusgyjRDqB0wg6bD8I7CTosP1Td6/rZ/1VwJfDTuAZwKOc7AR+CZhGcGaQcJ3d1AksMnw27z3KivAy0fqdhwC4pDyfBTMrmD+znIvK8vTg2XnqjDuB3b3DzJYAKwhu2XzI3evM7F6g1t2XD7BtnZk9QdC52wF8zt07wwadUueZ7JiIDI2pE/KYOmEqn7t+Kjv2H2dF3W5W1O3mgZfe5rsvvk1NaS7zZ5Yzf0Y5s6vGKQzGAD0IJiID2nu4lRfq97Cibje/2dJMZ5czcVwWH5hWSk1pHtUlOVSX5jKlJEe3mZ6j9CSwiJy1g8fbeHHjXp7fsIu1Ow7SdLSt1/IJ+ZlUlwRhUF2a22s6L1PhkKiuLqfp2AkaD7bSeLCFnQda+NMrJ5N7hv8Nz+Y5ABERAApzMrj98ipuv7wKCEYvfbf5ONubjwXfTcH3K2/v4ydrGnptW5qXEQZCLtUlOUwpze05e0i2ZxJa2ztpPNhC48FWdh48zs7wQN94sIWdB1vYdbCVts6uXtt8YFopl1YUDGk7dAYgIsPi2IkO3m0+zrvNx9gefm8LA2L34dZe6xbnZgRnCuEZQ03pyaAozMkYpT04M+5O87G2nl/uO8MDfePBFhoPBWXNx3qfOZlBWX4WlUXZTCzMZmJhFpWF2VQWds9nU5CVdsb9LjoDEJERlZuZxvSJBUyfeOqv1pa2Tt7bfzwMhJMB8btt+/mPtTuJ/i4dl50e6WfIZVJRNtkZqaSlpJCWYqSmGukpKaSmGGmpRmpK7/m0FCMtJSVcL1ielpLSs25aWJbowbW1vZPdh1rZebD74N4S+TUfTJ/o6P3rPScjlYnhAX3GxHFUFmb1zE8szKZ8XBbpozCAnwJAREZcdkYqF5fnc3F5/inLWts72bH/eE8obG8+xvam46x59wA/+69GuobpokV3EKSnpvQEQxAgJ+cPt3bQdPTEKdtOyM9kYmE20ycWcOP0MiaOCw/wRcFBflx2+jl515QCQETOKVnpqUwry2da2anhcKKjs+f6eEen09nltHd10dnldHQ6HV1ddHQ5ndHpLqe90+nsZz7YLpzvmQ63j8y3d3aRm5HW6zJNVWEOZeMyz9sRVxUAInLeyExLpbpUTycPFb01QkQkSSkARESSlAJARCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSkARESSlAJARCRJKQBERJJUQgFgZvPNbJOZbTazpXGWf9bM1pvZWjN7zcymh+V3hGXdny4zmxMuWxXW2b1swtDumoiIDGTQsYDMLBV4ELgRaABWm9lyd6+PrPaou/8gXH8hcD8w390fAR4Jy2cBz7j72sh2d7i7BvgXERkFiZwBzAM2u/tWd28DHgduja7g7ocjs7lAvAFbPw48dqYNFRGRoZXIaKCVwI7IfANwZd+VzOxzwJeADOCGOPX8CX2CA3jYzDqBp4BveZzXk5nZYmAxwOTJkxNoroiIJCKRM4B4bzE45UDt7g+6+4XAV4Cv9arA7ErguLtviBTf4e6zgN8PP5+I98fdfZm7x9w9Nn78+ASaKyIiiUgkABqASZH5KqBxgPUfB27rU7aIPpd/3H1n+H0EeJTgUpOIiIyQRAJgNTDNzGrMLIPgYL48uoKZTYvM3gK8E1mWAvwxQTB0l6WZWWk4nQ58BIieHYiIyDAbtA/A3TvMbAmwAkgFHnL3OjO7F6h19+XAEjP7ENAOHAA+GaniGqDB3bdGyjKBFeHBPxV4EfjhkOyRiIgkxOL0u56zYrGY19bqrlERkdNhZmvcPda3XE8Ci4gkKQWAiEiSUgCIiCQpBYCISJJSAIiIJCkFgIhIklIAiIgkKQWAiEiSUgCIiCQpBYCISJJSAIiIJCkFgIhIklIAiIgkKQWAiEiSUgCIiCQpBYCISJJSAIiIJKmEAsDM5pvZJjPbbGZL4yz/rJmtN7O1ZvaamU0Py6vNrCUsX2tmP4hsc3m4zWYz+56Z2dDtloiIDGbQADCzVOBBYAEwHfh49wE+4lF3n+Xuc4D7gPsjy7a4+5zw89lI+feBxcC08DP/LPZDREROUyJnAPOAze6+1d3bgMeBW6MruPvhyGwuMOCLhs2sAihw99968FLifwVuO62Wi4jIWUkkACqBHZH5hrCsFzP7nJltITgDuCeyqMbM3jSzV8zs9yN1NgxWp4iIDJ9EAiDetflTfuG7+4PufiHwFeBrYfEuYLK7zwW+BDxqZgWJ1glgZovNrNbMavft25dAc0VEJBGJBEADMCkyXwU0DrD+44SXc9z9hLs3h9NrgC3ARWGdVYnU6e7L3D3m7rHx48cn0FwREUlEIgGwGphmZjVmlgEsApZHVzCzaZHZW4B3wvLxYScyZnYBQWfvVnffBRwxs6vCu3/+DHjmrPdGREQSljbYCu7eYWZLgBVAKvCQu9eZ2b1ArbsvB5aY2YeAduAA8Mlw82uAe82sA+gEPuvu+8NldwM/BrKB58KPiIiMEAtuwjk/xGIxr62tHe1miIicV8xsjbvH+pbrSWARkSSlABARSVIKABGRJKUAEBFJUgoAEZEkpQAQEUlSCgARkSSlABARSVIKABGRJKUAEBFJUgoAEZEkpQAQEUlSCgARkSSlABARSVIKABGRJKUAEBFJUgoAEZEkpQAQEUlSCQWAmc03s01mttnMlsZZ/lkzW29ma83sNTObHpbfaGZrwmVrzOyGyDarwjrXhp8JQ7dbIiIymEFfCm9mqcCDwI1AA7DazJa7e31ktUfd/Qfh+guB+4H5QBPwUXdvNLOZBC+Wr4xsd4e76yW/IiKjIJEzgHnAZnff6u5twOPArdEV3P1wZDYX8LD8TXdvDMvrgCwzyzz7ZouIyNlKJAAqgR2R+QZ6/4oHwMw+Z2ZbgPuAe+LU80fAm+5+IlL2cHj55+tmZvH+uJktNrNaM6vdt29fAs0VEZFEJBIA8Q7MfkqB+4PufiHwFeBrvSowmwH8PfDfIsV3uPss4PfDzyfi/XF3X+buMXePjR8/PoHmiohIIhIJgAZgUmS+CmjsZ10ILhHd1j1jZlXA08CfufuW7nJ33xl+HwEeJbjUJCIiIySRAFgNTDOzGjPLABYBy6MrmNm0yOwtwDtheSHwc+Cr7v7ryPppZlYaTqcDHwE2nM2OiIjI6Rn0LiB37zCzJQR38KQCD7l7nZndC9S6+3JgiZl9CGgHDgCfDDdfAkwFvm5mXw/LbgKOASvCg38q8CLwwyHcLxERGYS5n3I5/5wVi8W8tlZ3jYqInA4zW+Pusb7lehJYRCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSkARESSlAJARCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSkARESSlAJARCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSUUAGY238w2mdlmM1saZ/lnzWy9ma01s9fMbHpk2VfD7TaZ2YcTrVNERIbXoAFgZqnAg8ACYDrw8egBPvSou89y9znAfcD94bbTCV4iPwOYD/wfM0tNsE4RERlGiZwBzAM2u/tWd28DHgduja7g7ocjs7lA94uGbwUed/cT7r4N2BzWN2idIiIyvNISWKcS2BGZbwCu7LuSmX0O+BKQAdwQ2fb1PttWhtOD1hnWuxhYDDB58uQEmisiIolI5AzA4pT5KQXuD7r7hcBXgK8Nsm1CdYb1LnP3mLvHxo8fn0BzRUQkEYmcATQAkyLzVUDjAOs/Dnw/gW1Pp04RERliiZwBrAammVmNmWUQdOouj65gZtMis7cA74TTy4FFZpZpZjXANOB3idQpIiLDa9AzAHfvMLMlwAogFXjI3evM7F6g1t2XA0vM7ENAO3AA+GS4bZ2ZPQHUAx3A59y9EyBenUO/eyIi0h9zj3vp/ZwUi8W8trZ2tJshInJeMbM17h7rW64ngUVEkpQCQEQkSSkARESSlAJARCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSkARESSlAJARCRJKQBERJKUAkBEJEkpAEREkpQCQEQkSSkARESSlAJARCRJKQBERJJUQgFgZvPNbJOZbTazpXGWf8nM6s1snZm9ZGZTwvLrzWxt5NNqZreFy35sZtsiy+YM7a6JiMhABn0nsJmlAg8CNwINwGozW+7u9ZHV3gRi7n7czO4G7gP+xN1XAnPCeoqBzcALke3+0t2fHJpdGcB7b0DbEcgpOflJzwGzYf/TIlX6ch8AAAqlSURBVCLnqkEDAJgHbHb3rQBm9jhwK8GL3gEID/TdXgfujFPP7cBz7n78zJt7hl69Dza/2LssLSsMg2LILu4dDt3lfafTs0e86SIiwyWRAKgEdkTmG4ArB1j/08BzccoXAff3Kfu2mf0N8BKw1N1P9N3IzBYDiwEmT56cQHPj+Mh34fAuON4cfFr2n5w+Hk7vXhcuO9B/Pek5ccIh/GQXxQ+RtMwza7OIyDBLJADiXSfxuCua3QnEgGv7lFcAs4AVkeKvAruBDGAZ8BXg3lP+kPuycDmxWCzu3x1U4eTgk4jODmg9GAmISEj0nd6/LZg/caj/+jLygyDILYWc0iAYcksi02F5bhgamQW6NCUiIyKRAGgAJkXmq4DGviuZ2YeAvwaujfNL/mPA0+7e3l3g7rvCyRNm9jDw5dNp+LBJTQsOyrmliW/T2X4yGHqdXTTDse7pJjiyC/bUBdMdrf38/Yzw7KG0/+DILe29Tkrq0Oy7iCSVRAJgNTDNzGqAnQSXcv40uoKZzQX+GZjv7nvj1PFxgl/80W0q3H2XmRlwG7DhDNp/bkhNh/yy4JMId2g7FgRBT0g0wbGmk2HRXdb4ZjDd71mGnbz81BMM4XTuBMjr/pQF3zrDEJHQoAHg7h1mtoTg8k0q8JC715nZvUCtuy8H/gHIA34SHM95z90XAphZNcEZxCt9qn7EzMYTXGJaC3x2SPbofGAGmXnBp6g6sW062iJnFt1hsT8yHc43b4EdbwTredep9aRlRYKhLPI9PvwOy3InQEbOkO62iJxbzP3MLquPhlgs5rW1taPdjPNDV1fQoX10T/A5tu/k9NG94XdYdryZuN06GfmJBUXueEjLGPFdFJHEmNkad4/1LU/kEpCcj1JSgj6D3BIomz7wup3twVnEQEGxpw62rOz/UlR2cSQoJkQ6tvt2dpdCVmHQPhEZVQoACfowCiqCz2DaW+HY3kg4dAfF3pPTO34XXI5qOxK/DksNb6WNdGhHA6LvfHZx0DkvIkNK/6+S05Oelfhtte2tffosmiP9Fc0ny7rvjBroGYyswoFDom8nuB7aExmUAkCGT3oWjKsMPono7Ahuo40XEt1lx5pg/9bwLKMZvDN+XWnZYRhEHtDreeI78h0t0/AgkmQUAHLuSE072YeQiK6uoE+i7220Pc9i7D/5fMbBHUF5y0H6eY4xuEOqV0gU9wmOSKB0l2XkKjTkvKUAkPNXSkrwDER2ETA1sW26OoMQOGVYkMh3d9nuDZHhQfoJjZ4H9/oOB1Lc58wjEiwZeQoNOScoACS5pKSevDsqUV2d0Hro1OFAThlTan/Qn9ESTg8WGn2D4ZRLVZFAUWjIMFAAiAwmJfXkJSGmJbZNT2jsj3O20efy1N76k2ca8R7eA0hJ73N2Ebk8lZ4dhEpaZpzvzOAZjdSMyHT0OzO4Cyw1/FbIJBUFgMhw6BUaiV6e6goHIuzvDCNyiWrvxsFD47RZ/CBJzegTGOGytMyg4zw9Jwih6HdGtDy6LLd3WVqmQmcUKQBEzhUpKacfGu7Q2QYdJ3p/n1J2IhhOpNey7rLosr5lJ/rU2QZtR4Pw6WgNbvVtPw7tLcF3f5e9+mMp/QTFQMESBkl3yGTkhdO5Qad8dFoBMyAFgMj5zOzkr/HR5h6GQkvvUGhvCQY/bG+Js+x4/PXbW4KQ6VvWfuz0zngsJX4wnBIe/U332TZrXNDZP0YeTBwbeyEio8/s5C95iofnb3Sf8bQdC4Kh7dip0wMt655uPQxHdvcubz+NlxVmjutzS3Bx78777L63ERefkw8nKgBE5PzR64xniEOmq+tkEPQXHt0d+71uH26CprcHHv4Eej+cGH3e5JSwiCzPzB/WS1gKABERCPpguodpP1MdbUHHfEvf50r2n+y07y7bvS6cHuA5k5T08PmSYlj0KJRceOZti0MBICIyVNIyTu/lUND77q/usIgXIJn5Q9/cIa9RREQS1+vurxH+0yP+F0VE5JyQUACY2Xwz22Rmm81saZzlXzKzejNbZ2YvmdmUyLJOM1sbfpZHymvM7A0ze8fM/t3M9EopEZERNGgAmFkq8CCwAJgOfNzM+r5i6k0g5u6zgSeB+yLLWtx9TvhZGCn/e+C77j4NOAB8+iz2Q0RETlMiZwDzgM3uvtXd24DHgVujK7j7Snfvvon2daBqoAoteHP8DQRhAfB/gdtOp+EiInJ2EgmASmBHZL4hLOvPp4HnIvNZZlZrZq+bWfdBvgQ46O4dg9VpZovD7Wv37duXQHNFRCQRidwFFO8phLg3rZrZnUAMuDZSPNndG83sAuBlM1sPHE60TndfBiwDiMVipznQiIiI9CeRM4AGYFJkvgpo7LuSmX0I+Gtgobuf6C5398bweyuwCpgLNAGFZtYdQHHrFBGR4ZNIAKwGpoV37WQAi4Dl0RXMbC7wzwQH/72R8iIzywynS4GrgXp3d2AlcHu46ieBZ852Z0REJHEWHIsHWcnsZuABIBV4yN2/bWb3ArXuvtzMXgRmAbvCTd5z94Vm9n6CYOgiCJsH3P1fwjovIOhQLia4i+jO6JlDP+3YB7x7BvsJUEpw5pFMtM/JQfs89p3t/k5x9/F9CxMKgLHAzGrdPTba7RhJ2ufkoH0e+4Zrf/UksIhIklIAiIgkqWQKgGWj3YBRoH1ODtrnsW9Y9jdp+gBERKS3ZDoDEBGRCAWAiEiSSooAGGw467HEzCaZ2Uoz22hmdWb2+dFu00gxs1Qze9PMnh3ttowEMys0syfN7K3wf+/fG+02DTcz+2L473qDmT1mZlmj3aahZmYPmdleM9sQKSs2s1+Gw+f/0syKhuJvjfkASHA467GkA/gf7n4pcBXwuTG+v1GfBzaOdiNG0D8Cz7v7JcD7GOP7bmaVwD0EQ8/PJHgwddHotmpY/BiY36dsKfBSOHz+S+H8WRvzAUACw1mPJe6+y93/M5w+QnBQGGj01jHBzKqAW4AfjXZbRoKZFQDXAP8C4O5t7n5wdFs1ItKA7HAcsRzG4Bhi7v4qsL9P8a0Ew+bDEA6fnwwBcLrDWY8ZZlZNMPjeG6PbkhHxAPA/CYYdSQYXAPuAh8PLXj8ys9zRbtRwcvedwHeA9wiGnTnk7i+MbqtGTJm774LgRx4wYSgqTYYASHg467HEzPKAp4AvuHu84bfHDDP7CLDX3deMdltGUBpwGfB9d58LHGOILgucq8Lr3rcCNcBEIDccgl7OUDIEQELDWY8lZpZOcPB/xN1/OtrtGQFXAwvNbDvBJb4bzOz/jW6Thl0D0ODu3Wd3TxIEwlj2IWCbu+9z93bgp8D7R7lNI2WPmVUAhN97B1k/IckQAIMOZz2WhK/b/Bdgo7vfP9rtGQnu/lV3r3L3aoL/fV929zH9y9DddwM7zOzisOiDQP0oNmkkvAdcZWY54b/zDzLGO74jlhMMmw9DOHx+Im8EO6+5e4eZLQFWcHI467pRbtZwuhr4BLDezNaGZX/l7r8YxTbJ8PjvwCPhD5utwKdGuT3Dyt3fMLMngf8kuNvtTcbgkBBm9hhwHVBqZg3A/wL+DnjCzD5NEIR/PCR/S0NBiIgkp2S4BCQiInEoAEREkpQCQEQkSSkARESSlAJARCRJKQBERJKUAkBEJEn9f0Q6Qxy3qoUbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history1.history['val_loss'], label = 'validation')\n",
    "pyplot.plot(history1.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=300, mode = 'min')\n",
    "mc = ModelCheckpoint('/Users/rsruti/Documents/Projects/Py-Scripts/EarlyStopping.model', monitor='val_accuracy', mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(500, activation='relu',input_dim = 2))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.6694 - acc: 0.6857 - val_loss: 0.6656 - val_acc: 0.5667\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.6316 - acc: 0.8000 - val_loss: 0.6506 - val_acc: 0.5667\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.5952 - acc: 0.8143 - val_loss: 0.6370 - val_acc: 0.6000\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.5630 - acc: 0.8286 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.5328 - acc: 0.8286 - val_loss: 0.6114 - val_acc: 0.6000\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.5061 - acc: 0.8286 - val_loss: 0.6006 - val_acc: 0.6000\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.4835 - acc: 0.8286 - val_loss: 0.5917 - val_acc: 0.6000\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.4625 - acc: 0.8429 - val_loss: 0.5827 - val_acc: 0.6333\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 93us/step - loss: 0.4449 - acc: 0.8429 - val_loss: 0.5723 - val_acc: 0.6333\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.4279 - acc: 0.8429 - val_loss: 0.5632 - val_acc: 0.6333\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 116us/step - loss: 0.4145 - acc: 0.8429 - val_loss: 0.5553 - val_acc: 0.6333\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.4012 - acc: 0.8429 - val_loss: 0.5486 - val_acc: 0.6333\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 105us/step - loss: 0.3889 - acc: 0.8429 - val_loss: 0.5413 - val_acc: 0.6333\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 102us/step - loss: 0.3776 - acc: 0.8286 - val_loss: 0.5329 - val_acc: 0.6333\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 111us/step - loss: 0.3679 - acc: 0.8286 - val_loss: 0.5262 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.3584 - acc: 0.8286 - val_loss: 0.5195 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 116us/step - loss: 0.3499 - acc: 0.8286 - val_loss: 0.5124 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.3422 - acc: 0.8286 - val_loss: 0.5067 - val_acc: 0.6667\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.3352 - acc: 0.8286 - val_loss: 0.5007 - val_acc: 0.6667\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 135us/step - loss: 0.3294 - acc: 0.8286 - val_loss: 0.4952 - val_acc: 0.6667\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.3229 - acc: 0.8286 - val_loss: 0.4865 - val_acc: 0.7333\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 104us/step - loss: 0.3177 - acc: 0.8286 - val_loss: 0.4800 - val_acc: 0.7333\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 102us/step - loss: 0.3128 - acc: 0.8286 - val_loss: 0.4724 - val_acc: 0.7333\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.3092 - acc: 0.8429 - val_loss: 0.4642 - val_acc: 0.7333\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8429 - val_loss: 0.4598 - val_acc: 0.7333\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.3010 - acc: 0.8429 - val_loss: 0.4553 - val_acc: 0.7667\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.2978 - acc: 0.8429 - val_loss: 0.4473 - val_acc: 0.7667\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.2948 - acc: 0.8429 - val_loss: 0.4377 - val_acc: 0.7667\n",
      "Epoch 29/1000\n",
      "32/70 [============>.................] - ETA: 0s - loss: 0.3035 - acc: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 100us/step - loss: 0.2914 - acc: 0.8429 - val_loss: 0.4306 - val_acc: 0.7667\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 113us/step - loss: 0.2888 - acc: 0.8429 - val_loss: 0.4224 - val_acc: 0.8000\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2858 - acc: 0.8429 - val_loss: 0.4143 - val_acc: 0.8000\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 116us/step - loss: 0.2835 - acc: 0.8429 - val_loss: 0.4059 - val_acc: 0.8000\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.2815 - acc: 0.8429 - val_loss: 0.4007 - val_acc: 0.8000\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.2795 - acc: 0.8429 - val_loss: 0.3975 - val_acc: 0.8000\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2769 - acc: 0.8429 - val_loss: 0.3974 - val_acc: 0.8000\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.2744 - acc: 0.8429 - val_loss: 0.3986 - val_acc: 0.8000\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 108us/step - loss: 0.2719 - acc: 0.8429 - val_loss: 0.3975 - val_acc: 0.8000\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.2698 - acc: 0.8429 - val_loss: 0.3970 - val_acc: 0.8000\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.2675 - acc: 0.8429 - val_loss: 0.4002 - val_acc: 0.8000\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 122us/step - loss: 0.2656 - acc: 0.8429 - val_loss: 0.4069 - val_acc: 0.8000\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 107us/step - loss: 0.2642 - acc: 0.8429 - val_loss: 0.4112 - val_acc: 0.8000\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.2616 - acc: 0.8571 - val_loss: 0.4081 - val_acc: 0.8000\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2602 - acc: 0.8571 - val_loss: 0.4037 - val_acc: 0.8000\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.2585 - acc: 0.8571 - val_loss: 0.4031 - val_acc: 0.8000\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 109us/step - loss: 0.2570 - acc: 0.8571 - val_loss: 0.4001 - val_acc: 0.8000\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 131us/step - loss: 0.2557 - acc: 0.8571 - val_loss: 0.3970 - val_acc: 0.8000\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.2543 - acc: 0.8571 - val_loss: 0.3945 - val_acc: 0.8000\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 111us/step - loss: 0.2530 - acc: 0.8571 - val_loss: 0.3934 - val_acc: 0.8000\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.2513 - acc: 0.8571 - val_loss: 0.3957 - val_acc: 0.8000\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.2502 - acc: 0.8571 - val_loss: 0.3980 - val_acc: 0.8000\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.2490 - acc: 0.8571 - val_loss: 0.4040 - val_acc: 0.8000\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.2483 - acc: 0.8714 - val_loss: 0.4105 - val_acc: 0.8000\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.2478 - acc: 0.8714 - val_loss: 0.4139 - val_acc: 0.8333\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 106us/step - loss: 0.2469 - acc: 0.8714 - val_loss: 0.4131 - val_acc: 0.8333\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.2459 - acc: 0.8714 - val_loss: 0.4139 - val_acc: 0.8000\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2447 - acc: 0.8714 - val_loss: 0.4114 - val_acc: 0.8333\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2432 - acc: 0.8714 - val_loss: 0.4053 - val_acc: 0.8333\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.2426 - acc: 0.8714 - val_loss: 0.3977 - val_acc: 0.8333\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.2409 - acc: 0.8714 - val_loss: 0.3972 - val_acc: 0.8333\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2393 - acc: 0.8714 - val_loss: 0.3983 - val_acc: 0.8333\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2384 - acc: 0.8857 - val_loss: 0.3997 - val_acc: 0.8333\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.2377 - acc: 0.8857 - val_loss: 0.3969 - val_acc: 0.8333\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.2372 - acc: 0.8714 - val_loss: 0.3949 - val_acc: 0.8333\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.2362 - acc: 0.8857 - val_loss: 0.3957 - val_acc: 0.8333\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 116us/step - loss: 0.2353 - acc: 0.8857 - val_loss: 0.3916 - val_acc: 0.8333\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.2339 - acc: 0.8857 - val_loss: 0.3901 - val_acc: 0.8333\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.2332 - acc: 0.8857 - val_loss: 0.3891 - val_acc: 0.8667\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2320 - acc: 0.8857 - val_loss: 0.3897 - val_acc: 0.8667\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.2311 - acc: 0.8857 - val_loss: 0.3912 - val_acc: 0.8333\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 129us/step - loss: 0.2306 - acc: 0.8857 - val_loss: 0.3927 - val_acc: 0.8333\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.2299 - acc: 0.8857 - val_loss: 0.3961 - val_acc: 0.8333\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.2295 - acc: 0.8857 - val_loss: 0.4006 - val_acc: 0.8333\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.2292 - acc: 0.8857 - val_loss: 0.3997 - val_acc: 0.8333\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.2284 - acc: 0.8857 - val_loss: 0.3960 - val_acc: 0.8333\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 116us/step - loss: 0.2277 - acc: 0.8857 - val_loss: 0.3899 - val_acc: 0.8667\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 106us/step - loss: 0.2262 - acc: 0.8857 - val_loss: 0.3855 - val_acc: 0.8667\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 99us/step - loss: 0.2254 - acc: 0.8857 - val_loss: 0.3815 - val_acc: 0.8667\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 108us/step - loss: 0.2246 - acc: 0.8857 - val_loss: 0.3802 - val_acc: 0.8667\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.2241 - acc: 0.8857 - val_loss: 0.3793 - val_acc: 0.8667\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.2239 - acc: 0.8857 - val_loss: 0.3733 - val_acc: 0.8667\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2225 - acc: 0.8714 - val_loss: 0.3685 - val_acc: 0.8667\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.2224 - acc: 0.8857 - val_loss: 0.3626 - val_acc: 0.8667\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.2242 - acc: 0.8857 - val_loss: 0.3593 - val_acc: 0.8667\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2228 - acc: 0.8857 - val_loss: 0.3639 - val_acc: 0.8667\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2219 - acc: 0.8857 - val_loss: 0.3663 - val_acc: 0.8667\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.2211 - acc: 0.8714 - val_loss: 0.3716 - val_acc: 0.8667\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.2199 - acc: 0.8714 - val_loss: 0.3797 - val_acc: 0.8667\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.2212 - acc: 0.8857 - val_loss: 0.3893 - val_acc: 0.8667\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.2196 - acc: 0.8857 - val_loss: 0.3896 - val_acc: 0.8667\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 72us/step - loss: 0.2191 - acc: 0.8857 - val_loss: 0.3907 - val_acc: 0.8667\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2191 - acc: 0.8857 - val_loss: 0.3937 - val_acc: 0.8667\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.2186 - acc: 0.8857 - val_loss: 0.3962 - val_acc: 0.8667\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.2185 - acc: 0.8857 - val_loss: 0.3973 - val_acc: 0.8333\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.2183 - acc: 0.8857 - val_loss: 0.4005 - val_acc: 0.8333\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.2183 - acc: 0.8857 - val_loss: 0.4035 - val_acc: 0.8333\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.2181 - acc: 0.8857 - val_loss: 0.4006 - val_acc: 0.8333\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 102us/step - loss: 0.2176 - acc: 0.8857 - val_loss: 0.3905 - val_acc: 0.8667\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.2156 - acc: 0.8857 - val_loss: 0.3834 - val_acc: 0.8667\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 93us/step - loss: 0.2140 - acc: 0.8857 - val_loss: 0.3734 - val_acc: 0.8667\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.2139 - acc: 0.8857 - val_loss: 0.3633 - val_acc: 0.8667\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.2151 - acc: 0.8857 - val_loss: 0.3532 - val_acc: 0.9000\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.2163 - acc: 0.8857 - val_loss: 0.3488 - val_acc: 0.9000\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.2161 - acc: 0.9000 - val_loss: 0.3479 - val_acc: 0.9000\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2155 - acc: 0.9000 - val_loss: 0.3458 - val_acc: 0.9000\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2158 - acc: 0.9000 - val_loss: 0.3448 - val_acc: 0.9000\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.2151 - acc: 0.9000 - val_loss: 0.3491 - val_acc: 0.9000\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.2131 - acc: 0.9000 - val_loss: 0.3549 - val_acc: 0.9000\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.2117 - acc: 0.8857 - val_loss: 0.3617 - val_acc: 0.8667\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.2112 - acc: 0.9000 - val_loss: 0.3703 - val_acc: 0.8667\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.2106 - acc: 0.8857 - val_loss: 0.3766 - val_acc: 0.8667\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.2100 - acc: 0.8857 - val_loss: 0.3765 - val_acc: 0.8667\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.2101 - acc: 0.8857 - val_loss: 0.3726 - val_acc: 0.8667\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.2089 - acc: 0.8857 - val_loss: 0.3743 - val_acc: 0.8667\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.2083 - acc: 0.8857 - val_loss: 0.3752 - val_acc: 0.8667\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.2079 - acc: 0.8857 - val_loss: 0.3746 - val_acc: 0.8667\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.2074 - acc: 0.8857 - val_loss: 0.3703 - val_acc: 0.8667\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.2079 - acc: 0.8857 - val_loss: 0.3642 - val_acc: 0.8667\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.2072 - acc: 0.9000 - val_loss: 0.3635 - val_acc: 0.8667\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.2057 - acc: 0.8857 - val_loss: 0.3723 - val_acc: 0.8667\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2047 - acc: 0.8857 - val_loss: 0.3855 - val_acc: 0.8667\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.2060 - acc: 0.8857 - val_loss: 0.3986 - val_acc: 0.8333\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.2072 - acc: 0.8857 - val_loss: 0.4080 - val_acc: 0.8333\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2097 - acc: 0.9000 - val_loss: 0.4118 - val_acc: 0.8333\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.2090 - acc: 0.9143 - val_loss: 0.4045 - val_acc: 0.8333\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.2070 - acc: 0.8857 - val_loss: 0.3956 - val_acc: 0.8667\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.2057 - acc: 0.8857 - val_loss: 0.3866 - val_acc: 0.8667\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.2040 - acc: 0.8857 - val_loss: 0.3851 - val_acc: 0.8667\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.2034 - acc: 0.8857 - val_loss: 0.3857 - val_acc: 0.8667\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.2035 - acc: 0.8857 - val_loss: 0.3887 - val_acc: 0.8667\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.2035 - acc: 0.9000 - val_loss: 0.3898 - val_acc: 0.8667\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.2029 - acc: 0.9000 - val_loss: 0.3875 - val_acc: 0.8667\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.2023 - acc: 0.9000 - val_loss: 0.3859 - val_acc: 0.8667\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.2017 - acc: 0.9000 - val_loss: 0.3852 - val_acc: 0.8667\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.2017 - acc: 0.9000 - val_loss: 0.3872 - val_acc: 0.8667\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.2009 - acc: 0.9000 - val_loss: 0.3882 - val_acc: 0.8667\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.2007 - acc: 0.9000 - val_loss: 0.3892 - val_acc: 0.8667\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.2008 - acc: 0.9000 - val_loss: 0.3879 - val_acc: 0.8667\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.1992 - acc: 0.9000 - val_loss: 0.3791 - val_acc: 0.8667\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.1984 - acc: 0.9000 - val_loss: 0.3719 - val_acc: 0.8667\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.1975 - acc: 0.9000 - val_loss: 0.3684 - val_acc: 0.8667\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.1970 - acc: 0.9000 - val_loss: 0.3665 - val_acc: 0.8667\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.1968 - acc: 0.9000 - val_loss: 0.3633 - val_acc: 0.8667\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.1968 - acc: 0.9143 - val_loss: 0.3519 - val_acc: 0.9000\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1972 - acc: 0.9000 - val_loss: 0.3459 - val_acc: 0.9000\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 93us/step - loss: 0.1965 - acc: 0.9143 - val_loss: 0.3446 - val_acc: 0.9000\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.1961 - acc: 0.9143 - val_loss: 0.3440 - val_acc: 0.9000\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.1953 - acc: 0.9143 - val_loss: 0.3450 - val_acc: 0.9000\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.1945 - acc: 0.9143 - val_loss: 0.3468 - val_acc: 0.9000\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.1935 - acc: 0.9143 - val_loss: 0.3500 - val_acc: 0.9000\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1928 - acc: 0.9000 - val_loss: 0.3541 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1923 - acc: 0.9143 - val_loss: 0.3593 - val_acc: 0.8667\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 120us/step - loss: 0.1928 - acc: 0.9143 - val_loss: 0.3606 - val_acc: 0.8667\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.1916 - acc: 0.9143 - val_loss: 0.3525 - val_acc: 0.9000\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 110us/step - loss: 0.1905 - acc: 0.9143 - val_loss: 0.3467 - val_acc: 0.9000\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1907 - acc: 0.9286 - val_loss: 0.3452 - val_acc: 0.9000\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.1900 - acc: 0.9286 - val_loss: 0.3457 - val_acc: 0.9000\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.1895 - acc: 0.9286 - val_loss: 0.3480 - val_acc: 0.9000\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1880 - acc: 0.9143 - val_loss: 0.3533 - val_acc: 0.8667\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.1875 - acc: 0.9143 - val_loss: 0.3608 - val_acc: 0.8667\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1881 - acc: 0.9143 - val_loss: 0.3710 - val_acc: 0.8667\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.1887 - acc: 0.9143 - val_loss: 0.3778 - val_acc: 0.8667\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1888 - acc: 0.9143 - val_loss: 0.3763 - val_acc: 0.8667\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1879 - acc: 0.9143 - val_loss: 0.3747 - val_acc: 0.8667\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.1870 - acc: 0.9143 - val_loss: 0.3692 - val_acc: 0.8667\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1847 - acc: 0.9143 - val_loss: 0.3587 - val_acc: 0.8667\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1837 - acc: 0.9286 - val_loss: 0.3474 - val_acc: 0.9000\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.1853 - acc: 0.9286 - val_loss: 0.3383 - val_acc: 0.9000\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1848 - acc: 0.9286 - val_loss: 0.3338 - val_acc: 0.9000\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1843 - acc: 0.9286 - val_loss: 0.3313 - val_acc: 0.9000\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.1847 - acc: 0.9286 - val_loss: 0.3283 - val_acc: 0.9000\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1834 - acc: 0.9286 - val_loss: 0.3291 - val_acc: 0.9000\n",
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1819 - acc: 0.9286 - val_loss: 0.3339 - val_acc: 0.9000\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.1802 - acc: 0.9286 - val_loss: 0.3424 - val_acc: 0.9000\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1810 - acc: 0.9143 - val_loss: 0.3481 - val_acc: 0.9000\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1798 - acc: 0.9143 - val_loss: 0.3494 - val_acc: 0.8667\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.1796 - acc: 0.9286 - val_loss: 0.3495 - val_acc: 0.8667\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.1785 - acc: 0.9286 - val_loss: 0.3540 - val_acc: 0.8667\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.1794 - acc: 0.9143 - val_loss: 0.3572 - val_acc: 0.8667\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1786 - acc: 0.9143 - val_loss: 0.3532 - val_acc: 0.8667\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1776 - acc: 0.9143 - val_loss: 0.3509 - val_acc: 0.8667\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1770 - acc: 0.9143 - val_loss: 0.3513 - val_acc: 0.8667\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1765 - acc: 0.9143 - val_loss: 0.3549 - val_acc: 0.8667\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.1771 - acc: 0.9143 - val_loss: 0.3584 - val_acc: 0.8667\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1772 - acc: 0.9143 - val_loss: 0.3593 - val_acc: 0.8667\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1766 - acc: 0.9286 - val_loss: 0.3577 - val_acc: 0.8667\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1757 - acc: 0.9143 - val_loss: 0.3558 - val_acc: 0.8667\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1749 - acc: 0.9143 - val_loss: 0.3499 - val_acc: 0.8667\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.1737 - acc: 0.9143 - val_loss: 0.3424 - val_acc: 0.9000\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1722 - acc: 0.9429 - val_loss: 0.3398 - val_acc: 0.9000\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1715 - acc: 0.9429 - val_loss: 0.3351 - val_acc: 0.9000\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1714 - acc: 0.9429 - val_loss: 0.3317 - val_acc: 0.9000\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1708 - acc: 0.9429 - val_loss: 0.3291 - val_acc: 0.9000\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1706 - acc: 0.9429 - val_loss: 0.3262 - val_acc: 0.9000\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1702 - acc: 0.9286 - val_loss: 0.3276 - val_acc: 0.9000\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1688 - acc: 0.9429 - val_loss: 0.3355 - val_acc: 0.9000\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.1685 - acc: 0.9429 - val_loss: 0.3430 - val_acc: 0.9000\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1686 - acc: 0.9429 - val_loss: 0.3451 - val_acc: 0.9000\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1686 - acc: 0.9286 - val_loss: 0.3448 - val_acc: 0.9000\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1683 - acc: 0.9286 - val_loss: 0.3492 - val_acc: 0.8667\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1687 - acc: 0.9286 - val_loss: 0.3509 - val_acc: 0.8667\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1682 - acc: 0.9286 - val_loss: 0.3435 - val_acc: 0.9000\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1655 - acc: 0.9429 - val_loss: 0.3269 - val_acc: 0.9000\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1652 - acc: 0.9286 - val_loss: 0.3158 - val_acc: 0.9333\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1651 - acc: 0.9286 - val_loss: 0.3105 - val_acc: 0.9333\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.1662 - acc: 0.9286 - val_loss: 0.3081 - val_acc: 0.9333\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.1661 - acc: 0.9286 - val_loss: 0.3094 - val_acc: 0.9333\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1653 - acc: 0.9286 - val_loss: 0.3155 - val_acc: 0.9333\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1626 - acc: 0.9286 - val_loss: 0.3196 - val_acc: 0.9333\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1620 - acc: 0.9286 - val_loss: 0.3248 - val_acc: 0.9000\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1621 - acc: 0.9286 - val_loss: 0.3313 - val_acc: 0.9000\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 66us/step - loss: 0.1614 - acc: 0.9429 - val_loss: 0.3379 - val_acc: 0.9000\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1623 - acc: 0.9429 - val_loss: 0.3470 - val_acc: 0.8667\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1627 - acc: 0.9429 - val_loss: 0.3508 - val_acc: 0.8667\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.1628 - acc: 0.9286 - val_loss: 0.3535 - val_acc: 0.8667\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1629 - acc: 0.9286 - val_loss: 0.3555 - val_acc: 0.8667\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1628 - acc: 0.9286 - val_loss: 0.3557 - val_acc: 0.8667\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1621 - acc: 0.9286 - val_loss: 0.3535 - val_acc: 0.8667\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1610 - acc: 0.9286 - val_loss: 0.3494 - val_acc: 0.8667\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1595 - acc: 0.9429 - val_loss: 0.3447 - val_acc: 0.9000\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1582 - acc: 0.9429 - val_loss: 0.3370 - val_acc: 0.9000\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1578 - acc: 0.9429 - val_loss: 0.3256 - val_acc: 0.9000\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.1557 - acc: 0.9429 - val_loss: 0.3202 - val_acc: 0.9000\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1552 - acc: 0.9429 - val_loss: 0.3184 - val_acc: 0.9000\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1546 - acc: 0.9429 - val_loss: 0.3171 - val_acc: 0.9000\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1543 - acc: 0.9429 - val_loss: 0.3152 - val_acc: 0.9000\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1533 - acc: 0.9429 - val_loss: 0.3155 - val_acc: 0.9000\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.1526 - acc: 0.9429 - val_loss: 0.3154 - val_acc: 0.9000\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1523 - acc: 0.9429 - val_loss: 0.3149 - val_acc: 0.9000\n",
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.1514 - acc: 0.9429 - val_loss: 0.3113 - val_acc: 0.9333\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.1508 - acc: 0.9429 - val_loss: 0.3099 - val_acc: 0.9333\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1504 - acc: 0.9429 - val_loss: 0.3089 - val_acc: 0.9333\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1499 - acc: 0.9429 - val_loss: 0.3094 - val_acc: 0.9333\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.1492 - acc: 0.9429 - val_loss: 0.3114 - val_acc: 0.9333\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.1486 - acc: 0.9429 - val_loss: 0.3162 - val_acc: 0.9000\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1491 - acc: 0.9571 - val_loss: 0.3240 - val_acc: 0.9000\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1499 - acc: 0.9571 - val_loss: 0.3288 - val_acc: 0.9000\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1502 - acc: 0.9429 - val_loss: 0.3313 - val_acc: 0.9000\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1499 - acc: 0.9429 - val_loss: 0.3314 - val_acc: 0.9000\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1494 - acc: 0.9429 - val_loss: 0.3311 - val_acc: 0.9000\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1489 - acc: 0.9429 - val_loss: 0.3310 - val_acc: 0.9000\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1482 - acc: 0.9571 - val_loss: 0.3298 - val_acc: 0.9000\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1475 - acc: 0.9571 - val_loss: 0.3269 - val_acc: 0.9000\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1461 - acc: 0.9571 - val_loss: 0.3176 - val_acc: 0.9000\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1430 - acc: 0.9571 - val_loss: 0.3067 - val_acc: 0.9333\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1448 - acc: 0.9429 - val_loss: 0.2956 - val_acc: 0.9333\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.1450 - acc: 0.9429 - val_loss: 0.2902 - val_acc: 0.9333\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1450 - acc: 0.9429 - val_loss: 0.2871 - val_acc: 0.9333\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1452 - acc: 0.9429 - val_loss: 0.2861 - val_acc: 0.9333\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.1444 - acc: 0.9429 - val_loss: 0.2851 - val_acc: 0.9333\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1434 - acc: 0.9429 - val_loss: 0.2852 - val_acc: 0.9333\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1419 - acc: 0.9429 - val_loss: 0.2837 - val_acc: 0.9333\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1414 - acc: 0.9429 - val_loss: 0.2833 - val_acc: 0.9333\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1408 - acc: 0.9429 - val_loss: 0.2845 - val_acc: 0.9333\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1398 - acc: 0.9429 - val_loss: 0.2860 - val_acc: 0.9333\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1393 - acc: 0.9429 - val_loss: 0.2860 - val_acc: 0.9333\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1383 - acc: 0.9429 - val_loss: 0.2870 - val_acc: 0.9333\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1374 - acc: 0.9429 - val_loss: 0.2880 - val_acc: 0.9333\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1367 - acc: 0.9429 - val_loss: 0.2892 - val_acc: 0.9333\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1361 - acc: 0.9429 - val_loss: 0.2894 - val_acc: 0.9333\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1354 - acc: 0.9429 - val_loss: 0.2912 - val_acc: 0.9333\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1356 - acc: 0.9429 - val_loss: 0.2932 - val_acc: 0.9333\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1343 - acc: 0.9429 - val_loss: 0.2908 - val_acc: 0.9333\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1337 - acc: 0.9429 - val_loss: 0.2869 - val_acc: 0.9333\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1338 - acc: 0.9429 - val_loss: 0.2815 - val_acc: 0.9333\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1344 - acc: 0.9429 - val_loss: 0.2805 - val_acc: 0.9333\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1326 - acc: 0.9429 - val_loss: 0.2843 - val_acc: 0.9333\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1315 - acc: 0.9429 - val_loss: 0.2878 - val_acc: 0.9333\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1303 - acc: 0.9429 - val_loss: 0.2911 - val_acc: 0.9333\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.1304 - acc: 0.9571 - val_loss: 0.2939 - val_acc: 0.9333\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1301 - acc: 0.9571 - val_loss: 0.2941 - val_acc: 0.9333\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1295 - acc: 0.9571 - val_loss: 0.2905 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1286 - acc: 0.9571 - val_loss: 0.2871 - val_acc: 0.9333\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.1284 - acc: 0.9571 - val_loss: 0.2832 - val_acc: 0.9333\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1276 - acc: 0.9429 - val_loss: 0.2823 - val_acc: 0.9333\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1271 - acc: 0.9429 - val_loss: 0.2829 - val_acc: 0.9333\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1266 - acc: 0.9571 - val_loss: 0.2837 - val_acc: 0.9333\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.1263 - acc: 0.9571 - val_loss: 0.2842 - val_acc: 0.9333\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1257 - acc: 0.9571 - val_loss: 0.2827 - val_acc: 0.9333\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1251 - acc: 0.9571 - val_loss: 0.2826 - val_acc: 0.9333\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1247 - acc: 0.9571 - val_loss: 0.2843 - val_acc: 0.9333\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.1243 - acc: 0.9571 - val_loss: 0.2850 - val_acc: 0.9333\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1238 - acc: 0.9571 - val_loss: 0.2876 - val_acc: 0.9333\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1249 - acc: 0.9571 - val_loss: 0.2924 - val_acc: 0.9333\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.1239 - acc: 0.9571 - val_loss: 0.2917 - val_acc: 0.9333\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1234 - acc: 0.9571 - val_loss: 0.2895 - val_acc: 0.9333\n",
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1224 - acc: 0.9571 - val_loss: 0.2867 - val_acc: 0.9333\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1217 - acc: 0.9571 - val_loss: 0.2840 - val_acc: 0.9333\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1212 - acc: 0.9571 - val_loss: 0.2827 - val_acc: 0.9333\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1206 - acc: 0.9571 - val_loss: 0.2826 - val_acc: 0.9333\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1201 - acc: 0.9571 - val_loss: 0.2837 - val_acc: 0.9333\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.1199 - acc: 0.9571 - val_loss: 0.2829 - val_acc: 0.9333\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1194 - acc: 0.9571 - val_loss: 0.2824 - val_acc: 0.9333\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.1189 - acc: 0.9571 - val_loss: 0.2822 - val_acc: 0.9333\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 53us/step - loss: 0.1185 - acc: 0.9571 - val_loss: 0.2824 - val_acc: 0.9333\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1182 - acc: 0.9571 - val_loss: 0.2833 - val_acc: 0.9333\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1186 - acc: 0.9571 - val_loss: 0.2856 - val_acc: 0.9333\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.1178 - acc: 0.9571 - val_loss: 0.2819 - val_acc: 0.9333\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1167 - acc: 0.9571 - val_loss: 0.2776 - val_acc: 0.9333\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1156 - acc: 0.9571 - val_loss: 0.2744 - val_acc: 0.9333\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.1150 - acc: 0.9571 - val_loss: 0.2719 - val_acc: 0.9333\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.1146 - acc: 0.9571 - val_loss: 0.2692 - val_acc: 0.9333\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.1141 - acc: 0.9571 - val_loss: 0.2661 - val_acc: 0.9333\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.1144 - acc: 0.9714 - val_loss: 0.2599 - val_acc: 0.9333\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.1138 - acc: 0.9571 - val_loss: 0.2562 - val_acc: 0.9333\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1134 - acc: 0.9571 - val_loss: 0.2549 - val_acc: 0.9333\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.1130 - acc: 0.9571 - val_loss: 0.2561 - val_acc: 0.9333\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1120 - acc: 0.9714 - val_loss: 0.2610 - val_acc: 0.9333\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.1120 - acc: 0.9714 - val_loss: 0.2647 - val_acc: 0.9333\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0870 - acc: 1.000 - 0s 86us/step - loss: 0.1113 - acc: 0.9714 - val_loss: 0.2629 - val_acc: 0.9333\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.1110 - acc: 0.9714 - val_loss: 0.2578 - val_acc: 0.9333\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1099 - acc: 0.9714 - val_loss: 0.2560 - val_acc: 0.9333\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 104us/step - loss: 0.1095 - acc: 0.9714 - val_loss: 0.2562 - val_acc: 0.9333\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.1089 - acc: 0.9714 - val_loss: 0.2569 - val_acc: 0.9333\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.1085 - acc: 0.9714 - val_loss: 0.2570 - val_acc: 0.9333\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1078 - acc: 0.9714 - val_loss: 0.2585 - val_acc: 0.9333\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1072 - acc: 0.9714 - val_loss: 0.2604 - val_acc: 0.9333\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.1074 - acc: 0.9714 - val_loss: 0.2618 - val_acc: 0.9333\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.1067 - acc: 0.9714 - val_loss: 0.2592 - val_acc: 0.9333\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 110us/step - loss: 0.1059 - acc: 0.9714 - val_loss: 0.2583 - val_acc: 0.9333\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1056 - acc: 0.9714 - val_loss: 0.2570 - val_acc: 0.9333\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.1051 - acc: 0.9714 - val_loss: 0.2558 - val_acc: 0.9333\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.1047 - acc: 0.9714 - val_loss: 0.2549 - val_acc: 0.9333\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.1043 - acc: 0.9714 - val_loss: 0.2553 - val_acc: 0.9333\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.1039 - acc: 0.9714 - val_loss: 0.2567 - val_acc: 0.9333\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.1036 - acc: 0.9714 - val_loss: 0.2578 - val_acc: 0.9333\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.1032 - acc: 0.9714 - val_loss: 0.2580 - val_acc: 0.9333\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.1028 - acc: 0.9714 - val_loss: 0.2579 - val_acc: 0.9333\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.1030 - acc: 0.9714 - val_loss: 0.2581 - val_acc: 0.9333\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1019 - acc: 0.9714 - val_loss: 0.2547 - val_acc: 0.9333\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.1017 - acc: 0.9714 - val_loss: 0.2493 - val_acc: 0.9333\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1017 - acc: 0.9714 - val_loss: 0.2456 - val_acc: 0.9333\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 71us/step - loss: 0.1021 - acc: 0.9571 - val_loss: 0.2437 - val_acc: 0.9333\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.1015 - acc: 0.9571 - val_loss: 0.2440 - val_acc: 0.9333\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 104us/step - loss: 0.1009 - acc: 0.9714 - val_loss: 0.2455 - val_acc: 0.9333\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.1000 - acc: 0.9714 - val_loss: 0.2471 - val_acc: 0.9333\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0992 - acc: 0.9714 - val_loss: 0.2491 - val_acc: 0.9333\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0991 - acc: 0.9714 - val_loss: 0.2507 - val_acc: 0.9333\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0984 - acc: 0.9714 - val_loss: 0.2504 - val_acc: 0.9333\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0977 - acc: 0.9714 - val_loss: 0.2530 - val_acc: 0.9333\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.0977 - acc: 0.9714 - val_loss: 0.2555 - val_acc: 0.9333\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0975 - acc: 0.9714 - val_loss: 0.2583 - val_acc: 0.9333\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0979 - acc: 0.9714 - val_loss: 0.2625 - val_acc: 0.9333\n",
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0980 - acc: 0.9714 - val_loss: 0.2656 - val_acc: 0.9333\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0989 - acc: 0.9714 - val_loss: 0.2700 - val_acc: 0.9333\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0996 - acc: 0.9571 - val_loss: 0.2700 - val_acc: 0.9333\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0986 - acc: 0.9714 - val_loss: 0.2642 - val_acc: 0.9333\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0965 - acc: 0.9714 - val_loss: 0.2583 - val_acc: 0.9333\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0952 - acc: 0.9714 - val_loss: 0.2510 - val_acc: 0.9333\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0943 - acc: 0.9714 - val_loss: 0.2446 - val_acc: 0.9333\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0937 - acc: 0.9714 - val_loss: 0.2405 - val_acc: 0.9333\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0935 - acc: 0.9714 - val_loss: 0.2391 - val_acc: 0.9333\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0930 - acc: 0.9714 - val_loss: 0.2388 - val_acc: 0.9333\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0927 - acc: 0.9714 - val_loss: 0.2387 - val_acc: 0.9333\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0922 - acc: 0.9714 - val_loss: 0.2392 - val_acc: 0.9333\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0916 - acc: 0.9714 - val_loss: 0.2403 - val_acc: 0.9333\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0911 - acc: 0.9714 - val_loss: 0.2425 - val_acc: 0.9333\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0907 - acc: 0.9714 - val_loss: 0.2412 - val_acc: 0.9333\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0900 - acc: 0.9714 - val_loss: 0.2372 - val_acc: 0.9333\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0898 - acc: 0.9714 - val_loss: 0.2307 - val_acc: 0.9333\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0906 - acc: 0.9714 - val_loss: 0.2268 - val_acc: 0.9333\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0916 - acc: 0.9714 - val_loss: 0.2252 - val_acc: 0.9333\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0909 - acc: 0.9714 - val_loss: 0.2253 - val_acc: 0.9333\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0898 - acc: 0.9714 - val_loss: 0.2266 - val_acc: 0.9333\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0886 - acc: 0.9714 - val_loss: 0.2276 - val_acc: 0.9333\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0877 - acc: 0.9714 - val_loss: 0.2284 - val_acc: 0.9333\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0870 - acc: 0.9714 - val_loss: 0.2302 - val_acc: 0.9333\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0865 - acc: 0.9714 - val_loss: 0.2316 - val_acc: 0.9333\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0863 - acc: 0.9714 - val_loss: 0.2327 - val_acc: 0.9333\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0856 - acc: 0.9714 - val_loss: 0.2306 - val_acc: 0.9333\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0848 - acc: 0.9714 - val_loss: 0.2277 - val_acc: 0.9333\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0855 - acc: 0.9714 - val_loss: 0.2251 - val_acc: 0.9333\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0857 - acc: 0.9714 - val_loss: 0.2242 - val_acc: 0.9333\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0850 - acc: 0.9714 - val_loss: 0.2260 - val_acc: 0.9333\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0845 - acc: 0.9714 - val_loss: 0.2307 - val_acc: 0.9333\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0833 - acc: 0.9714 - val_loss: 0.2353 - val_acc: 0.9333\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0829 - acc: 0.9714 - val_loss: 0.2393 - val_acc: 0.9333\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0830 - acc: 0.9714 - val_loss: 0.2426 - val_acc: 0.9333\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0835 - acc: 0.9714 - val_loss: 0.2468 - val_acc: 0.9333\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0841 - acc: 0.9714 - val_loss: 0.2492 - val_acc: 0.9333\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0847 - acc: 0.9714 - val_loss: 0.2488 - val_acc: 0.9333\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0846 - acc: 0.9714 - val_loss: 0.2470 - val_acc: 0.9333\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0840 - acc: 0.9714 - val_loss: 0.2438 - val_acc: 0.9333\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0833 - acc: 0.9714 - val_loss: 0.2397 - val_acc: 0.9333\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0819 - acc: 0.9714 - val_loss: 0.2369 - val_acc: 0.9333\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0809 - acc: 0.9714 - val_loss: 0.2341 - val_acc: 0.9333\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0801 - acc: 0.9714 - val_loss: 0.2307 - val_acc: 0.9333\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0793 - acc: 0.9714 - val_loss: 0.2284 - val_acc: 0.9333\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0791 - acc: 0.9714 - val_loss: 0.2269 - val_acc: 0.9333\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0787 - acc: 0.9714 - val_loss: 0.2260 - val_acc: 0.9333\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0784 - acc: 0.9714 - val_loss: 0.2261 - val_acc: 0.9333\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0781 - acc: 0.9714 - val_loss: 0.2262 - val_acc: 0.9333\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0777 - acc: 0.9714 - val_loss: 0.2264 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0776 - acc: 0.9714 - val_loss: 0.2265 - val_acc: 0.9333\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0772 - acc: 0.9714 - val_loss: 0.2263 - val_acc: 0.9333\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0770 - acc: 0.9714 - val_loss: 0.2262 - val_acc: 0.9333\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0767 - acc: 0.9714 - val_loss: 0.2259 - val_acc: 0.9333\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0764 - acc: 0.9714 - val_loss: 0.2253 - val_acc: 0.9333\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0758 - acc: 0.9714 - val_loss: 0.2269 - val_acc: 0.9333\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0759 - acc: 0.9714 - val_loss: 0.2293 - val_acc: 0.9333\n",
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0754 - acc: 0.9714 - val_loss: 0.2278 - val_acc: 0.9333\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0752 - acc: 0.9714 - val_loss: 0.2254 - val_acc: 0.9333\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0746 - acc: 0.9714 - val_loss: 0.2253 - val_acc: 0.9333\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0744 - acc: 0.9714 - val_loss: 0.2232 - val_acc: 0.9333\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0743 - acc: 0.9714 - val_loss: 0.2211 - val_acc: 0.9333\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0738 - acc: 0.9714 - val_loss: 0.2219 - val_acc: 0.9333\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0733 - acc: 0.9714 - val_loss: 0.2195 - val_acc: 0.9333\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0732 - acc: 0.9714 - val_loss: 0.2138 - val_acc: 0.9333\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0723 - acc: 0.9857 - val_loss: 0.2113 - val_acc: 0.9333\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0723 - acc: 0.9857 - val_loss: 0.2107 - val_acc: 0.9333\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0718 - acc: 0.9857 - val_loss: 0.2119 - val_acc: 0.9333\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0714 - acc: 0.9857 - val_loss: 0.2134 - val_acc: 0.9333\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0711 - acc: 0.9857 - val_loss: 0.2156 - val_acc: 0.9333\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0707 - acc: 0.9714 - val_loss: 0.2175 - val_acc: 0.9333\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0703 - acc: 0.9714 - val_loss: 0.2192 - val_acc: 0.9333\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0701 - acc: 0.9714 - val_loss: 0.2202 - val_acc: 0.9333\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0700 - acc: 0.9714 - val_loss: 0.2203 - val_acc: 0.9333\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0697 - acc: 0.9714 - val_loss: 0.2201 - val_acc: 0.9333\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0693 - acc: 0.9714 - val_loss: 0.2189 - val_acc: 0.9333\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0690 - acc: 0.9714 - val_loss: 0.2171 - val_acc: 0.9333\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0688 - acc: 0.9714 - val_loss: 0.2157 - val_acc: 0.9333\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0686 - acc: 0.9714 - val_loss: 0.2148 - val_acc: 0.9333\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0683 - acc: 0.9714 - val_loss: 0.2144 - val_acc: 0.9333\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0681 - acc: 0.9714 - val_loss: 0.2136 - val_acc: 0.9333\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0678 - acc: 0.9714 - val_loss: 0.2138 - val_acc: 0.9333\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0674 - acc: 0.9714 - val_loss: 0.2133 - val_acc: 0.9333\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0671 - acc: 0.9714 - val_loss: 0.2127 - val_acc: 0.9333\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0668 - acc: 0.9714 - val_loss: 0.2125 - val_acc: 0.9333\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0666 - acc: 0.9714 - val_loss: 0.2124 - val_acc: 0.9333\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0666 - acc: 0.9714 - val_loss: 0.2103 - val_acc: 0.9333\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0661 - acc: 0.9714 - val_loss: 0.2080 - val_acc: 0.9333\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 105us/step - loss: 0.0659 - acc: 0.9857 - val_loss: 0.2062 - val_acc: 0.9333\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 98us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9333\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 97us/step - loss: 0.0664 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9333\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 90us/step - loss: 0.0663 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9333\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0663 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9667\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0670 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9667\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0671 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9667\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.0667 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9667\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0649 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9333\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 91us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9333\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0626 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9333\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0631 - acc: 0.9857 - val_loss: 0.2077 - val_acc: 0.9333\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0627 - acc: 0.9857 - val_loss: 0.2099 - val_acc: 0.9333\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0627 - acc: 0.9714 - val_loss: 0.2104 - val_acc: 0.9333\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0624 - acc: 0.9714 - val_loss: 0.2091 - val_acc: 0.9333\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0618 - acc: 0.9714 - val_loss: 0.2069 - val_acc: 0.9333\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0613 - acc: 0.9857 - val_loss: 0.2028 - val_acc: 0.9333\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0607 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9333\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0602 - acc: 1.0000 - val_loss: 0.2003 - val_acc: 0.9333\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0598 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9333\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0595 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9333\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0593 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9333\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 65us/step - loss: 0.0589 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9333\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9333\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9333\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0581 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9333\n",
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0580 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9333\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0578 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9333\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9333\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0573 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9333\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9333\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9333\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9333\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9333\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0559 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9333\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0559 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9333\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9333\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0555 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9333\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9333\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9333\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0547 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9333\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0545 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9333\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9333\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0540 - acc: 1.0000 - val_loss: 0.1968 - val_acc: 0.9333\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9333\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9333\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0534 - acc: 1.0000 - val_loss: 0.1937 - val_acc: 0.9667\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 0.1937 - val_acc: 0.9667\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0532 - acc: 1.0000 - val_loss: 0.1945 - val_acc: 0.9667\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.1947 - val_acc: 0.9667\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0526 - acc: 1.0000 - val_loss: 0.1931 - val_acc: 0.9667\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9667\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0523 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 0.9667\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0519 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9333\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9333\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0514 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9667\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0513 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 0.9667\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 0.9667\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0512 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 0.9667\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9667\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0505 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9333\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9333\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0498 - acc: 1.0000 - val_loss: 0.1929 - val_acc: 0.9333\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0496 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9333\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9333\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.1911 - val_acc: 0.9333\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0491 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9333\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0489 - acc: 1.0000 - val_loss: 0.1887 - val_acc: 0.9333\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0487 - acc: 1.0000 - val_loss: 0.1884 - val_acc: 0.9333\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9333\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9333\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9667\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9667\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9667\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.1817 - val_acc: 0.9667\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0475 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9667\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0468 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9667\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0463 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9333\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0459 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9333\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0463 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0463 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9333\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0466 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9333\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0466 - acc: 1.0000 - val_loss: 0.1954 - val_acc: 0.9333\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9333\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9333\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9333\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9333\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9667\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9667\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0446 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9667\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9667\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9667\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0443 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9667\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9667\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9667\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0428 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9667\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0425 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9667\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9333\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9333\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9333\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.1817 - val_acc: 0.9333\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0418 - acc: 1.0000 - val_loss: 0.1813 - val_acc: 0.9333\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9333\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.1814 - val_acc: 0.9333\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9333\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.1826 - val_acc: 0.9333\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.1828 - val_acc: 0.9333\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9333\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9333\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0406 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9333\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.1834 - val_acc: 0.9333\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9333\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9333\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9667\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9667\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9667\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9667\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9667\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 0.1767 - val_acc: 0.9667\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9667\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9667\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9667\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.1780 - val_acc: 0.9667\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9667\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.1826 - val_acc: 0.9667\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.9667\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9333\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9333\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9333\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9333\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9333\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.1929 - val_acc: 0.9333\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9333\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9333\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.1855 - val_acc: 0.9333\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9333\n",
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 0.9333\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9333\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.1817 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.1814 - val_acc: 0.9667\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9667\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9667\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9667\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9667\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9667\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9667\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.1767 - val_acc: 0.9667\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9667\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.1763 - val_acc: 0.9667\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9667\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9667\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9667\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9667\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0341 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9667\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9667\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.1733 - val_acc: 0.9667\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9667\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9667\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 0.9667\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.1755 - val_acc: 0.9667\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9667\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9667\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9667\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9667\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9667\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.1755 - val_acc: 0.9667\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 0.9667\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1729 - val_acc: 0.9667\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9667\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 0.9667\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9667\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9667\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 0.9667\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0318 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9667\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1717 - val_acc: 0.9667\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9667\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9667\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9667\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 0.9667\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9667\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9667\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9667\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.1840 - val_acc: 0.9667\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9667\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9667\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9667\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 0.9667\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9667\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9667\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.1869 - val_acc: 0.9667\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9667\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9667\n",
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9667\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.1834 - val_acc: 0.9667\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9667\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9667\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9667\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9667\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9667\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9667\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9667\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9667\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.1820 - val_acc: 0.9667\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9667\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9667\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9667\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9667\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9667\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.1760 - val_acc: 0.9667\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9667\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.1765 - val_acc: 0.9667\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 0.9667\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9667\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9667\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9667\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1820 - val_acc: 0.9667\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1828 - val_acc: 0.9667\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9667\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9667\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9667\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9667\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9667\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9667\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 0.9667\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9667\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9667\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9667\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9667\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9667\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9667\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9667\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9667\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9667\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9667\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 0.9667\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9667\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9667\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9667\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.1877 - val_acc: 0.9667\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9667\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9667\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9667\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9667\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9667\n",
      "Epoch 696/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 66us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.1873 - val_acc: 0.9667\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9667\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9667\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1884 - val_acc: 0.9667\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1884 - val_acc: 0.9667\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9667\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1887 - val_acc: 0.9667\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9667\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.1894 - val_acc: 0.9667\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9667\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9667\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9667\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 52us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9667\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 56us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9667\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9667\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9667\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9667\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9667\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 55us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.1779 - val_acc: 0.9667\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9667\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 0.9667\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1765 - val_acc: 0.9667\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9667\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9667\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9667\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.9667\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1757 - val_acc: 0.9667\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1764 - val_acc: 0.9667\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9667\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9667\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9667\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9667\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9667\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9667\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 54us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9667\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9667\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9667\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9667\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1786 - val_acc: 0.9667\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9667\n",
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9667\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9667\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9667\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9667\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9667\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.1776 - val_acc: 0.9667\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.1776 - val_acc: 0.9667\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9667\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9667\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9667\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9667\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9667\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 0.9667\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9667\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9667\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9667\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9667\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9667\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9667\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9667\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9667\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 60us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1807 - val_acc: 0.9667\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9667\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9667\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9667\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9667\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9667\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9667\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9667\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9667\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9667\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9667\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9667\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9667\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9667\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9667\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9667\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1819 - val_acc: 0.9667\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9667\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 57us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 58us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9667\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1807 - val_acc: 0.9667\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1795 - val_acc: 0.9667\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9667\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.1796 - val_acc: 0.9667\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.1802 - val_acc: 0.9667\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9667\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9667\n",
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 95us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9667\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 104us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 94us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 96us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9667\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1855 - val_acc: 0.9667\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 89us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1872 - val_acc: 0.9667\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9667\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9667\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 0.9667\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9667\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9667\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9667\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9667\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9667\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9667\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1910 - val_acc: 0.9667\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.1890 - val_acc: 0.9667\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 73us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.1869 - val_acc: 0.9667\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9667\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9667\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9667\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 88us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1779 - val_acc: 0.9667\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9667\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9667\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9667\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9667\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9667\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9667\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9667\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9667\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9667\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9667\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9667\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9667\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9667\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9667\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9667\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9667\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 92us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9667\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9667\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 83us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9667\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9667\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9667\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9667\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9667\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9667\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9667\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9667\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9667\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9667\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 64us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 0.9667\n",
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9667\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1860 - val_acc: 0.9667\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9667\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 62us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9667\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9667\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9667\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1869 - val_acc: 0.9667\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9667\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9667\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9667\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 72us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1816 - val_acc: 0.9667\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9667\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9667\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9667\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1786 - val_acc: 0.9667\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9667\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 78us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9667\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1804 - val_acc: 0.9667\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9667\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9667\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 59us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9667\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9667\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9667\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9667\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 84us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9667\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9667\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9667\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9667\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9667\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 87us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.9667\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9667\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9667\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 80us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9667\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 61us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9667\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9667\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 75us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9667\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 63us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9667\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9667\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 73us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9667\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 70us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9667\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 68us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.9667\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 69us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9667\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 67us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9667\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 74us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1888 - val_acc: 0.9667\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 66us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9667\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 76us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1910 - val_acc: 0.9667\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 77us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9667\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 65us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9667\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 79us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=32, epochs = 1000, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history2.history['val_loss'][600:], label = 'validation')\n",
    "pyplot.plot(history2.history['loss'][600:], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
